# Project Overview
Generated on: Tue Jul 29 14:46:55 EDT 2025

This script produces a comprehensive snapshot of all files in the ranked-choice project.
Sensitive data could be exposed, so protect 'project-overview.txt' accordingly.
---

## 1. Directory Structure

Below is the tree of files/folders (excluding .git, node_modules, dist, project-overview*):
```
.
├── .DS_Store
├── .env
├── .env.example
├── .gitignore
├── .nvmrc
├── AGENTS.md
├── docs
│   ├── .DS_Store
│   ├── feelings.json
│   ├── field-notes.md
│   ├── other-branch-snapshots
│   │   ├── .DS_Store
│   │   ├── develop (latest-stable)
│   │   └── field-notes-c01 (earlier attempt at field notes feature)
│   └── parallel-playbook.md
├── package-lock.json
├── package.json
├── photo-select-here.sh
├── prompts
│   ├── default_prompt_olympia.txt
│   ├── default_prompt.hbs
│   └── default_prompt.txt
├── README.md
├── scripts
│   ├── demote-thumb.js
│   ├── generate-overview.sh
│   └── migrate-notes.js
├── src
│   ├── batchContext.js
│   ├── chatClient.js
│   ├── config.js
│   ├── errorHandler.js
│   ├── fieldNotesWriter.js
│   ├── imageSelector.js
│   ├── index.js
│   ├── orchestrator.js
│   ├── providers
│   │   ├── index.js
│   │   ├── ollama.js
│   │   └── openai.js
│   └── templates.js
└── tests
    ├── chatClient.test.js
    ├── fieldNotesWriter.test.js
    ├── imageSelector.test.js
    └── orchestrator.test.js

10 directories, 37 files
```

---

## 2. Full Content Dump
This section provides a textual representation of each file, skipping certain directories and file patterns.
PDF files are extracted as text if possible; binary files are noted but not shown in raw form.

### File: .
```
(File type is inode/directory — skipping raw dump.)
```

### File: ./photo-select-here.sh
```
#!/usr/bin/env bash
set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
TARGET_DIR="$(pwd)"

# Load nvm if available
if [ -z "${NVM_DIR:-}" ]; then
  if [ -d "$HOME/.nvm" ]; then
    export NVM_DIR="$HOME/.nvm"
  fi
fi
if [ -s "$NVM_DIR/nvm.sh" ]; then
  . "$NVM_DIR/nvm.sh"
fi

# Use Node version from .nvmrc if nvm is available
if command -v nvm >/dev/null 2>&1; then
  if ! nvm use "$SCRIPT_DIR" >/dev/null 2>&1; then
    echo "nvm: Node $(cat "$SCRIPT_DIR/.nvmrc") not installed; using system node $(node --version)" >&2
  fi
fi

cd "$SCRIPT_DIR"

# Optional memory tweak for large batches
if [ -n "${PHOTO_SELECT_MAX_OLD_SPACE_MB:-}" ]; then
  export NODE_OPTIONS="${NODE_OPTIONS:-} --max-old-space-size=${PHOTO_SELECT_MAX_OLD_SPACE_MB}"
fi


dir_specified=false
for arg in "$@"; do
  case "$arg" in
    -d|--dir|--dir=*|-d=*)
      dir_specified=true
      break
      ;;
  esac
done

if [ "$dir_specified" = true ]; then
  npx photo-select "$@"
else
  npx photo-select "$@" --dir "$TARGET_DIR"
fi
```

### File: ./.DS_Store
```
(File type is application/octet-stream — skipping raw dump.)
```

### File: ./tests
```
(File type is inode/directory — skipping raw dump.)
```

### File: ./tests/orchestrator.test.js
```
import { describe, it, expect, vi, beforeEach, afterEach } from "vitest";
import fs from "node:fs/promises";
import path from "node:path";
import os from "node:os";

vi.hoisted(() => {
  process.env.OPENAI_API_KEY = "test";
});

vi.mock("../src/chatClient.js", async () => {
  const actual = await vi.importActual("../src/chatClient.js");
  return {
    ...actual,
    chatCompletion: vi.fn(),
  };
});

import { chatCompletion } from "../src/chatClient.js";
import { triageDirectory } from "../src/orchestrator.js";

let tmpDir;
let promptFile;

beforeEach(async () => {
  tmpDir = await fs.mkdtemp(path.join(os.tmpdir(), "ps-test-"));
  await fs.writeFile(path.join(tmpDir, "1.jpg"), "a");
  await fs.writeFile(path.join(tmpDir, "2.jpg"), "b");
  promptFile = path.join(tmpDir, "prompt.txt");
  await fs.writeFile(promptFile, "prompt");
});

afterEach(async () => {
  vi.restoreAllMocks();
  await fs.rm(tmpDir, { recursive: true, force: true });
});

describe("triageDirectory", () => {
  it("moves files into keep and aside", async () => {
    chatCompletion.mockResolvedValueOnce(
      JSON.stringify({ keep: ["1.jpg"], aside: ["2.jpg"] })
    );
    await triageDirectory({
      dir: tmpDir,
      promptPath: promptFile,
      model: "test-model",
      recurse: false,
    });
    const keepPath = path.join(tmpDir, "_keep", "1.jpg");
    const asidePath = path.join(tmpDir, "_aside", "2.jpg");
    await expect(fs.stat(keepPath)).resolves.toBeTruthy();
    await expect(fs.stat(asidePath)).resolves.toBeTruthy();
    const level = path.join(tmpDir, "_level-001", "1.jpg");
    await expect(fs.stat(level)).resolves.toBeTruthy();
  });

  it("recurses into keep directory", async () => {
    chatCompletion
      .mockResolvedValueOnce(JSON.stringify({ keep: ["1.jpg"], aside: ["2.jpg"] }))
      .mockResolvedValueOnce(JSON.stringify({ keep: [], aside: ["1.jpg"] }));
    await triageDirectory({
      dir: tmpDir,
      promptPath: promptFile,
      model: "test-model",
      recurse: true,
    });
    expect(chatCompletion).toHaveBeenCalledTimes(2);
    const aside2 = path.join(tmpDir, "_keep", "_aside", "1.jpg");
    await expect(fs.stat(aside2)).resolves.toBeTruthy();
    const level2 = path.join(tmpDir, "_keep", "_level-002", "1.jpg");
    await expect(fs.stat(level2)).resolves.toBeTruthy();
  });

  it("recurses even when all images kept", async () => {
    chatCompletion
      .mockResolvedValueOnce(
        JSON.stringify({ keep: ["1.jpg", "2.jpg"], aside: [] })
      )
      .mockResolvedValueOnce(
        JSON.stringify({ keep: [], aside: ["1.jpg", "2.jpg"] })
      );
    await triageDirectory({
      dir: tmpDir,
      promptPath: promptFile,
      model: "test-model",
      recurse: true,
    });
    expect(chatCompletion).toHaveBeenCalledTimes(2);
    const aside2 = path.join(tmpDir, "_keep", "_aside", "2.jpg");
    await expect(fs.stat(aside2)).resolves.toBeTruthy();
  });

  it("processes batches in parallel", async () => {
    chatCompletion
      .mockResolvedValueOnce(JSON.stringify({ keep: ["1.jpg"], aside: [] }))
      .mockResolvedValueOnce(JSON.stringify({ keep: [], aside: ["2.jpg"] }));
    await triageDirectory({
      dir: tmpDir,
      promptPath: promptFile,
      model: "test-model",
      recurse: false,
      parallel: 2,
    });
    expect(chatCompletion).toHaveBeenCalledTimes(2);
    const keepPath = path.join(tmpDir, "_keep", "1.jpg");
    const asidePath = path.join(tmpDir, "_aside", "2.jpg");
    await expect(fs.stat(keepPath)).resolves.toBeTruthy();
    await expect(fs.stat(asidePath)).resolves.toBeTruthy();
  });

  it("retries after chat errors", async () => {
    chatCompletion
      .mockRejectedValueOnce(new Error("timeout"))
      .mockResolvedValueOnce(JSON.stringify({ keep: ["1.jpg"], aside: ["2.jpg"] }));
    await triageDirectory({
      dir: tmpDir,
      promptPath: promptFile,
      model: "test-model",
      recurse: false,
    });
    expect(chatCompletion).toHaveBeenCalledTimes(2);
    const keepPath = path.join(tmpDir, "_keep", "1.jpg");
    const asidePath = path.join(tmpDir, "_aside", "2.jpg");
    await expect(fs.stat(keepPath)).resolves.toBeTruthy();
    await expect(fs.stat(asidePath)).resolves.toBeTruthy();
  });
});
```

### File: ./tests/chatClient.test.js
```
import { describe, it, expect, beforeAll, afterAll, vi } from "vitest";
import fs from "node:fs/promises";
import os from "node:os";
import path from "node:path";

let chatSpy;
let responsesSpy;

class MockNotFoundError extends Error {
  constructor(msg) {
    super(msg);
    this.status = 404;
  }
}

vi.mock("openai", () => {
  chatSpy = vi.fn();
  responsesSpy = vi.fn();
  return {
    OpenAI: vi.fn(() => ({
      chat: { completions: { create: chatSpy } },
      responses: { create: responsesSpy },
    })),
    NotFoundError: MockNotFoundError,
  };
});

let parseReply, buildMessages, buildInput, chatCompletion, curatorsFromTags;
beforeAll(async () => {
  process.env.OPENAI_API_KEY = 'test-key';
  global.fetch = vi.fn(async () => ({ ok: true, json: async () => ({ data: [] }) }));
  ({ parseReply, buildMessages, buildInput, chatCompletion, curatorsFromTags } = await import('../src/chatClient.js'));
});

afterAll(() => {
  global.fetch = undefined;
});

const files = [
  "/tmp/DSCF1234.jpg",
  "/tmp/DSCF5678.jpg",
  "/tmp/DSCF9012.jpg",
];

/** Basic parsing of keep/aside directives */
describe("parseReply", () => {
  it("classifies mentioned files and captures notes", () => {
    const reply = `DSCF1234.jpg -- keep - sharp shot\nSet aside: DSCF5678.jpg - blurry`;
    const { keep, aside, notes } = parseReply(reply, files);
    expect(keep).toContain(files[0]);
    expect(notes.get(files[0])).toMatch(/sharp/);
    expect(aside).toContain(files[1]);
    expect(notes.get(files[1])).toMatch(/blurry/);
  });

  it("leaves unmentioned files unclassified", () => {
    const reply = `keep: DSCF1234.jpg`;
    const { aside, keep, unclassified } = parseReply(reply, files);
    expect(keep).toContain(files[0]);
    expect(unclassified).toContain(files[1]);
    expect(unclassified).toContain(files[2]);
  });

  it("matches filenames when the reply omits prefixes", () => {
    const prefixed = [
      "/tmp/2020-01-01-DSCF1234.jpg",
      "/tmp/2020-01-01-DSCF5678.jpg",
    ];
    const reply = `DSCF1234.jpg -- keep\nSet aside: DSCF5678.jpg`;
    const { keep, aside } = parseReply(reply, prefixed);
    expect(keep).toContain(prefixed[0]);
    expect(aside).toContain(prefixed[1]);
  });

  it("parses JSON responses with reasoning", () => {
    const json = JSON.stringify({
      keep: { "DSCF1234.jpg": "good light" },
      aside: { "DSCF5678.jpg": "out of focus" },
    });
    const { keep, aside, notes } = parseReply(json, files);
    expect(keep).toContain(files[0]);
    expect(notes.get(files[0])).toMatch(/good light/);
    expect(aside).toContain(files[1]);
    expect(notes.get(files[1])).toMatch(/out of focus/);
    expect(aside).not.toContain(files[2]);
  });

  it("handles JSON wrapped in Markdown fences", () => {
    const fenced =
      '```json\n' +
      JSON.stringify({ keep: ["DSCF1234.jpg"], aside: ["DSCF5678.jpg"] }) +
      '\n```';
    const { keep, aside } = parseReply(fenced, files);
    expect(keep).toContain(files[0]);
    expect(aside).toContain(files[1]);
  });

  it("deduplicates files listed in both groups", () => {
    const reply = JSON.stringify({ keep: ["DSCF1234.jpg"], aside: ["DSCF1234.jpg"] });
    const { keep, aside } = parseReply(reply, files);
    expect(keep).toContain(files[0]);
    expect(aside).not.toContain(files[0]);
  });

  it("parses minutes and nested decision", () => {
    const reply = JSON.stringify({
      minutes: [{ speaker: "Curator", text: "looks good" }],
      decision: { keep: ["DSCF1234.jpg"], aside: ["DSCF5678.jpg"] },
    });
    const { keep, aside, minutes } = parseReply(reply, files);
    expect(minutes[0]).toMatch(/Curator/);
    expect(keep).toContain(files[0]);
    expect(aside).toContain(files[1]);
  });

  it("extracts field note instructions", () => {
    const obj = {
      decision: { keep: [], aside: [] },
      field_notes_instructions: "Add note",
    };
    const { fieldNotesInstructions } = parseReply(JSON.stringify(obj), files, {
      expectFieldNotesInstructions: true,
    });
    expect(fieldNotesInstructions).toBe("Add note");
  });

  it("extracts field notes markdown", () => {
    const obj = { field_notes_md: "notes" };
    const { fieldNotesMd } = parseReply(JSON.stringify(obj), files, {
      expectFieldNotesMd: true,
    });
    expect(fieldNotesMd).toBe("notes");
  });

  it("extracts commit message", () => {
    const obj = { field_notes_md: "notes", commit_message: "Add note" };
    const { commitMessage } = parseReply(JSON.stringify(obj), files, {
      expectFieldNotesMd: true,
    });
    expect(commitMessage).toBe("Add note");
  });
});

/** Verify images are labelled in messages */
describe("buildMessages", () => {
  it("labels each image before the encoded data", async () => {
    const dir = await fs.mkdtemp(path.join(os.tmpdir(), "ps-msg-"));
    const img1 = path.join(dir, "1.jpg");
    const img2 = path.join(dir, "2.jpg");
    await fs.writeFile(img1, "a");
    await fs.writeFile(img2, "b");
    const { messages } = await buildMessages("prompt", [img1, img2]);
    const [, user] = messages;
    expect(JSON.parse(user.content[1].text)).toEqual({ filename: "1.jpg" });
    expect(JSON.parse(user.content[3].text)).toEqual({ filename: "2.jpg" });
    await fs.rm(dir, { recursive: true, force: true });
  });

  it("includes people names when available", async () => {
    const dir = await fs.mkdtemp(path.join(os.tmpdir(), "ps-msg-"));
    const img1 = path.join(dir, "a.jpg");
    await fs.writeFile(img1, "a");
    global.fetch.mockResolvedValueOnce({
      ok: true,
      json: async () => ({ data: ["Alice", "Bob"] }),
    });
    const { messages } = await buildMessages("prompt", [img1]);
    const [, user] = messages;
    const meta = JSON.parse(user.content[1].text);
    expect(meta.filename).toBe("a.jpg");
    expect(meta.people).toEqual(["Alice", "Bob"]);
    await fs.rm(dir, { recursive: true, force: true });
  });
});

describe("buildInput", () => {
  it("labels each image before the encoded data", async () => {
    const dir = await fs.mkdtemp(path.join(os.tmpdir(), "ps-in-"));
    const img1 = path.join(dir, "1.jpg");
    await fs.writeFile(img1, "a");
    const { input } = await buildInput("prompt", [img1]);
    const meta = JSON.parse(input[0].content[1].text);
    expect(meta).toEqual({ filename: "1.jpg" });
    await fs.rm(dir, { recursive: true, force: true });
  });

  it("includes people names when available", async () => {
    const dir = await fs.mkdtemp(path.join(os.tmpdir(), "ps-in-"));
    const img1 = path.join(dir, "a.jpg");
    await fs.writeFile(img1, "a");
    global.fetch.mockResolvedValueOnce({
      ok: true,
      json: async () => ({ data: ["Alice", "Bob"] }),
    });
    const { input } = await buildInput("prompt", [img1]);
    const meta = JSON.parse(input[0].content[1].text);
    expect(meta.filename).toBe("a.jpg");
    expect(meta.people).toEqual(["Alice", "Bob"]);
    await fs.rm(dir, { recursive: true, force: true });
  });
});

describe("curatorsFromTags", () => {
  it("returns names appearing in multiple files", async () => {
    const imgs = ["/tmp/x1.jpg", "/tmp/x2.jpg", "/tmp/x3.jpg"];
    global.fetch
      .mockResolvedValueOnce({ ok: true, json: async () => ({ data: ["Alice"] }) })
      .mockResolvedValueOnce({ ok: true, json: async () => ({ data: ["Bob"] }) })
      .mockResolvedValueOnce({ ok: true, json: async () => ({ data: ["Alice"] }) });
    const names = await curatorsFromTags(imgs);
    expect(names).toContain("Alice");
  });

  it("filters placeholder names", async () => {
    const imgs = ["/tmp/y1.jpg", "/tmp/y2.jpg"];
    global.fetch
      .mockResolvedValueOnce({ ok: true, json: async () => ({ data: ["_UNKNOWN_"] }) })
      .mockResolvedValueOnce({ ok: true, json: async () => ({ data: ["_UNKNOWN_"] }) });
    const names = await curatorsFromTags(imgs);
    expect(names).toHaveLength(0);
    global.fetch.mockReset();
  });
});

describe("chatCompletion", () => {
  let chatCompletion;

  beforeAll(async () => {
    ({ chatCompletion } = await import("../src/chatClient.js"));
  });

  it("falls back to responses when chat endpoint not supported", async () => {
    const errMsg =
      "This is not a chat model and thus not supported in the v1/chat/completions endpoint. Did you mean to use v1/completions?";
    chatSpy.mockRejectedValueOnce(new MockNotFoundError(errMsg));
    responsesSpy.mockResolvedValueOnce({ output_text: "ok" });
    const result = await chatCompletion({
      prompt: "p",
      images: [],
      model: "o3-pro",
      cache: false,
    });
    expect(responsesSpy).toHaveBeenCalled();
    const args = responsesSpy.mock.calls[0][0];
    expect(args.max_output_tokens).toBeTruthy();
    expect(result).toBe("ok");
  });

  it("logs additional curators from tags", async () => {
    vi.resetModules();
    const { chatCompletion } = await import("../src/chatClient.js");
    const dir = await fs.mkdtemp(path.join(os.tmpdir(), "ps-cur-"));
    const img1 = path.join(dir, "1.jpg");
    const img2 = path.join(dir, "2.jpg");
    await fs.writeFile(img1, "a");
    await fs.writeFile(img2, "b");
    global.fetch
      .mockResolvedValueOnce({ ok: true, json: async () => ({ data: ["Alice"] }) })
      .mockResolvedValueOnce({ ok: true, json: async () => ({ data: ["Alice"] }) });
    chatSpy.mockResolvedValueOnce({ choices: [{ message: { content: "{}" } }] });
    const logSpy = vi.spyOn(console, "log").mockImplementation(() => {});
    await chatCompletion({
      prompt: "p {{curators}}",
      images: [img1, img2],
      model: "gpt-4o",
      cache: false,
      curators: ["Bob"],
    });
    expect(logSpy).toHaveBeenCalledWith(
      expect.stringContaining("Alice")
    );
    logSpy.mockRestore();
    await fs.rm(dir, { recursive: true, force: true });
  });
});
```

### File: ./tests/imageSelector.test.js
```
import { describe, it, expect } from "vitest";
import { pickRandom } from "../src/imageSelector.js";

describe("pickRandom", () => {
  it("returns no more than requested items", () => {
    const arr = [...Array(20).keys()];
    const result = pickRandom(arr, 10);
    expect(result.length).toBeLessThanOrEqual(10);
  });

  it("returns every item when array shorter than count", () => {
    const arr = [1, 2, 3];
    expect(pickRandom(arr, 10)).toHaveLength(3);
  });
});
```

### File: ./tests/fieldNotesWriter.test.js
```
import { describe, it, expect, beforeEach, afterEach, vi } from "vitest";
import fs from "node:fs/promises";
import path from "node:path";
import os from "node:os";
import { execFile } from "node:child_process";
import { promisify } from "node:util";
import FieldNotesWriter from "../src/fieldNotesWriter.js";

const exec = promisify(execFile);

async function generateDiff(oldStr, newStr) {
  const dir = await fs.mkdtemp(path.join(os.tmpdir(), "diff-"));
  const a = path.join(dir, "a.md");
  const b = path.join(dir, "b.md");
  await fs.writeFile(a, oldStr);
  await fs.writeFile(b, newStr);
  const { stdout } = await exec("diff", ["-u", "--label", "a/field-notes.md", a, "--label", "b/field-notes.md", b]).catch((e) => ({ stdout: e.stdout }));
  await fs.rm(dir, { recursive: true, force: true });
  return stdout;
}

describe("FieldNotesWriter", () => {
  let dir;
  let file;
  let writer;
  beforeEach(async () => {
    dir = await fs.mkdtemp(path.join(os.tmpdir(), "fnw-"));
    file = path.join(dir, "field-notes.md");
    await fs.writeFile(path.join(dir, "DSCF1.jpg"), "");
    await fs.writeFile(path.join(dir, "DSCF2.png"), "");
    await fs.writeFile(path.join(dir, "DSCF3.jpg"), "");
    await fs.writeFile(path.join(dir, "DSCF4.jpg"), "");
    writer = new FieldNotesWriter(file, "001");
  });
  afterEach(async () => {
    await fs.rm(dir, { recursive: true, force: true });
  });

  it("autolinks bare filenames", () => {
    const text = writer.autolink("See DSCF1.jpg and DSCF2.png");
    expect(text).toContain("[DSCF1.jpg](./DSCF1.jpg)");
    expect(text).toContain("[DSCF2.png](./DSCF2.png)");
  });

  it("adds warning when too many inline images", async () => {
    const md = "![](./DSCF1.jpg)\n![](./DSCF2.png)\n![](./DSCF3.jpg)\n![](./DSCF4.jpg)";
    await writer.writeFull(md);
    const text = await fs.readFile(file, "utf8");
    expect(text).toMatch(/Warning/);
  });

  it("applies diffs", async () => {
    await writer.writeFull("hello");
    const diff = await generateDiff("hello\n", "hello\nworld\n");
    await writer.applyDiff(diff);
    const result = await writer.read();
    expect(result.trim()).toBe("hello\nworld");
  });

  it("falls back when patch command fails", async () => {
    const failExec = vi.fn().mockRejectedValue(new Error("patch missing"));
    const w = new FieldNotesWriter(file, "001", failExec);
    await w.writeFull("hi");
    const diff = await generateDiff("hi\n", "hi there\n");
    await w.applyDiff(diff);
    const result = await w.read();
    expect(result.trim()).toBe("hi there");
  });

  it("throws when diff cannot apply", async () => {
    const failExec = vi.fn().mockRejectedValue(new Error("patch failed"));
    const w = new FieldNotesWriter(file, "001", failExec);
    await w.writeFull("hello\n");
    const badDiff = "--- a/field-notes.md\n+++ b/field-notes.md\n@@\n-foo\n+bar\n";
    await expect(w.applyDiff(badDiff)).rejects.toThrow();
  });
});
```

### File: ./docs
```
(File type is inode/directory — skipping raw dump.)
```

### File: ./docs/.DS_Store
```
(File type is application/octet-stream — skipping raw dump.)
```

### File: ./docs/parallel-playbook.md
```
# Tuning `--parallel`

This guide summarises a rule-of-thumb approach for choosing the `--parallel` flag when running `photo-select` on a single workstation. It assumes the OpenAI API calls dominate overall latency.

## 1. Identify bottlenecks

Check CPU, RAM, and disk usage while a batch is running. The network wait time for the API is usually the limiting factor.

## 2. Quick starting points

| Workstation | Suggested `--parallel` |
|-------------|-----------------------|
| 4 cores      | 4–6 |
| 8 cores      | 8–10 |
| 12+ high‑perf cores | 12–14 |

The workers spend most of their time waiting on network responses, so running about twice the physical core count generally saturates the connection without exhausting RAM.

## 3. Estimate from your own run

1. Measure how long one batch of images takes end‑to‑end.
2. Compare local preprocessing time (`T_prep`) with the API wait (`T_API`).
3. Set `parallel ≈ ceil(T_API / T_prep)` and add about 10–20 % headroom.

## 4. Verify

Run a short dry pass with the chosen value and watch CPU usage and any `Rate limit` errors. Bump the number up if the machine stays mostly idle; dial it back if you hit rate limits or file‑sync delays.

## 5. Troubleshooting

| Symptom | Cause | Remedy |
|---------|-------|--------|
| `429` or `Rate limit` | Exceeded OpenAI request limits | Lower `--parallel` or request higher quota |
| File-sync backlog | Too many writes (e.g., Google Drive) | Write to a local folder first |
| Memory creep | Large number of Node processes | Limit `--parallel` or lower `PHOTO_SELECT_MAX_OLD_SPACE_MB` |

```

### File: ./docs/field-notes.md
```
# Field Notes Workflow

The `--field-notes` flag enables a lightweight notebook that evolves alongside each directory level. When the flag is passed, a `field-notes.md` file is created next to every `_level-NNN` folder. After each batch of images is triaged the curators can update this file using a diff based workflow.

## How it works

1. On the first batch for a level the tool creates an empty `field-notes.md` with creation and update timestamps.
2. The current contents of the notebook are included in the prompt so the curators can propose additions or edits.
3. If the model returns a unified diff, it is applied to the notebook and the update timestamp is refreshed. A second pass may be triggered if the patch does not apply cleanly.
4. Bare filenames such as `DSCF0001.jpg` automatically link to images in the same directory.
5. When more than three inline images (`![]()`) appear in a single entry a warning is appended so the notes remain compact.
6. Include a brief description when linking or embedding images, e.g. `[cube overview](DSCF0001.jpg)` or `![cube overview](DSCF0001.jpg)`. The curatorial template now requires alt‑text for every reference.
7. If the target directory lacks a `.git` repository one is initialized automatically. Updates from the second pass are committed with the curator-provided message.
8. During the second pass the prompt also includes the two previous versions of `field-notes.md` (when available) along with the commit history for the current level.

Disable the feature by omitting the flag. Each level keeps its own notebook so progress can be reviewed later.

## Historical background

An early Python prototype used diffs to update the notebook. The revised workflow sends **instructions** for how to edit the notes. A second LLM call then applies those steps and returns the complete file through `field_notes_md`. This logic lives in `FieldNotesWriter` and `orchestrator.js`.

## Migrating legacy notes

Notebooks created by the Python prototype lack headers and automatic links. Run `node scripts/migrate-notes.js <file>` to convert them to the current format. The script rewrites each file using `FieldNotesWriter`, preserving original text while adding timestamps and autolinks.
```

### File: ./docs/other-branch-snapshots
```
(File type is inode/directory — skipping raw dump.)
```

### File: ./docs/other-branch-snapshots/develop (latest-stable)
```
(File type is inode/directory — skipping raw dump.)
```

### File: ./docs/other-branch-snapshots/.DS_Store
```
(File type is application/octet-stream — skipping raw dump.)
```

### File: ./docs/other-branch-snapshots/field-notes-c01 (earlier attempt at field notes feature)
```
(File type is inode/directory — skipping raw dump.)
```

### File: ./docs/feelings.json
```
[
  "amused",
  "anxious",
  "calm",
  "confident",
  "confused",
  "concerned",
  "curious",
  "delighted",
  "disappointed",
  "eager",
  "frustrated",
  "grateful",
  "hopeful",
  "inspired",
  "joyful",
  "lonely",
  "overwhelmed",
  "peaceful",
  "proud",
  "relieved",
  "sad",
  "surprised",
  "tired"
]
```

### File: ./README.md
```
# photo‑select

A command‑line workflow that **selects 10 random images, asks ChatGPT which to “keep” or “set aside,”
moves the files accordingly, and then recurses until a directory is fully triaged.**

---

## Requirements

- Node 20+
- An OpenAI API key (via `OPENAI_API_KEY` or the `--api-key` flag)
  ```bash
  export OPENAI_API_KEY="sk‑..."
  ```

* macOS, Linux, or Windows‑WSL (uses only cross‑platform Node APIs)

## Installation

```bash
cd photo-select
nvm install   # obeys .nvmrc (Node 20.x)
nvm use
```

### 2  Configure your API key

1. Copy the template:

   ```bash
   cp .env.example .env
   ```

2. Paste your real key in `.env`:

   ```dotenv
   OPENAI_API_KEY=sk-...
   ```

No need to `export` the key in every shell—`dotenv` loads it automatically.

### 3  Install dependencies

```bash
npm install
chmod +x src/index.js    # fix permission error when running with npx
```

Invoke the CLI from the project directory using `npx`:

```bash
npx photo-select \
  [--dir /path/to/images] \
  [--provider ollama] \
  [--model qwen2.5vl:32b] \
  [--api-key sk-...] \
  [--context /path/to/context.txt]
```

You can also install globally with `npm install -g` to run `photo-select` anywhere.

## Usage

```bash
# run from the project directory
npx photo-select --provider openai --model gpt-4o [other flags]
# or, if installed globally:
photo-select --provider ollama --model qwen2.5vl:32b [other flags]
```

Run `photo-select --help` to see all options.

### photo-select-here.sh

If you keep the repository cloned on your system, the `photo-select-here.sh`
script lets you run the CLI on whatever directory you're currently in without
typing `--dir` each time. Call it with the path to the script:

```bash
/path/to/photo-select/photo-select-here.sh [photo-select flags]
```

The script automatically:

1. Loads `nvm` and uses the Node version defined in `.nvmrc` if available.
2. Runs `npx photo-select` inside the repo.
3. Sets `--dir` to your current working directory unless you specify it
   explicitly.

### demote-thumb.js

Run `node scripts/demote-thumb.js <file> <image>` to convert an embedded
thumbnail to a plain link inside a Markdown file. The tool also appends
`~ Demoted: <image>` to the `Δ‑Summary` block, creating it if missing.

This helps you stay within the three‑thumbnail budget when curating notes.

All CLI flags—including `--api-key`, `--model`, and `--no-recurse`—can be passed
through to the script unchanged.

### Flags

| flag       | default                      | description                                     |
| ---------- | ---------------------------- | ----------------------------------------------- |
| `--dir`    | current directory            | Source directory containing images              |
| `--prompt` | `prompts/default_prompt.txt` | Path to a custom prompt file                    |
| `--provider` | `openai` | `openai` or `ollama` |
| `--model`  | *(auto)* | Model id for the chosen provider. Defaults to `gpt-4o` or `qwen2.5vl:32b`. |
| `--api-key` | *(unset)*                  | OpenAI API key. Overrides `$OPENAI_API_KEY`. |
| `--ollama-base-url` | `http://localhost:11434` | Ollama host URL |
| `--curators` | *(unset)* | Comma-separated list of curator names used in the group transcript |
| `--context` | *(unset)* | Text file with exhibition context for the curators |
| `--no-recurse` | `false` | Process only the given directory without descending into `_keep` |
| `--parallel` | `1` | Number of batches to process simultaneously |
| `--field-notes` | `false` | Enable notebook updates via field-notes workflow |

When enabled, the tool initializes a git repository in the target directory if one is absent and commits each notebook update using the model's commit message.
During the second pass the prompt includes the two prior versions of each notebook and the commit log for that level so curators can craft a self-contained update.

See [docs/field-notes.md](docs/field-notes.md) for a description of how the
notebook system works.

### Increasing memory

The Node.js heap defaults to about 4 GB. Large runs with `--parallel` greater than 1
may exhaust that limit. Set `PHOTO_SELECT_MAX_OLD_SPACE_MB` to allocate more memory:

```bash
PHOTO_SELECT_MAX_OLD_SPACE_MB=8192 \
  /path/to/photo-select/photo-select-here.sh --parallel 10 --api-key sk-...
```

The value is passed directly to `--max-old-space-size`, so adjust it to match your
available RAM.

### Choosing `--parallel`

Running multiple batches at once hides API latency but can exhaust system resources. See
[`docs/parallel-playbook.md`](docs/parallel-playbook.md) for a practical guide on
tuning this flag. In short, start around twice your physical core count and adjust
until network waits dominate without hitting OpenAI rate limits.

### Streaming responses

To avoid connection timeouts with large image batches, the CLI streams tokens
from OpenAI as soon as they are available. Progress bars advance to a
"stream" stage while data arrives. Streaming keeps the HTTPS socket alive and
reduces the chance of retry loops on slow requests.

### Custom timeout

Long vision batches can occasionally exceed the default 5‑minute HTTP timeout.
The client now waits up to **20 minutes** by default. Set `PHOTO_SELECT_TIMEOUT_MS`
to override this value if your environment needs a different window.

### JSON-only replies from Ollama

The Ollama provider now defaults to requesting JSON responses for reliable
parsing. Set `PHOTO_SELECT_OLLAMA_FORMAT` to override the `format` parameter or
leave it empty to disable.

```bash
export PHOTO_SELECT_OLLAMA_FORMAT=""  # omit format entirely
```

### People metadata (optional)

Set `PHOTO_FILTER_API_BASE` to the base URL of your [photo‑filter](https://github.com/openhouse/photo-filter) service to include face‑tag data in the prompt. The CLI assumes the service is available at `http://localhost:3000` when the variable is unset and logs a warning if requests fail. For each image it fetches `/api/photos/by-filename/<filename>/persons` and sends a JSON blob like `{ "filename": "DSCF1234.jpg", "people": ["Alice", "Bob"] }` before the image itself. Results are cached per filename for the duration of the run.

Example:

```bash
PHOTO_FILTER_API_BASE=http://localhost:3000 \
/path/to/photo-select/photo-select-here.sh --api-key sk-... --model o3 \
  --curators "Ingeborg Gerdes, Alexandra Munroe, Mandy Steinback, Kendell Harbin, Erin Zona, Madeline Gallucci, Deborah Treisman" \
  --context /path/to/info.md
```

## Supported OpenAI models

The CLI calls the Chat Completions API and automatically switches to `/v1/responses` if a model only supports that endpoint. Any vision-capable chat model listed on OpenAI's [models](https://platform.openai.com/docs/models) page should work, including:


* **GPT‑4.1 family** – `gpt-4.1`, `gpt-4.1-mini`, and `gpt-4.1-nano`
* **GPT‑4o family** – `gpt-4o` (default), `gpt-4o-mini`, `gpt-4o-audio-preview`,
  `gpt-4o-mini-audio-preview`, `gpt-4o-realtime-preview`,
  `gpt-4o-mini-realtime-preview`, `gpt-4o-search-preview`, and
  `gpt-4o-mini-search-preview`
* **o‑series reasoning models** – `o4-mini`, `o3`, `o3-pro` *(responses API)*,
  `o3-mini`, `o1`, `o1-pro`, and the deprecated `o1-mini`
* **Other vision models** – `gpt-4-turbo`, `gpt-4.5-preview` *(deprecated)*. The
  `gpt-4-vision-preview` model has been removed.

Example output of `openai api models.list`:

```text
gpt-4.1-nano
gpt-4.1-nano-2025-04-14
gpt-4.5-preview
gpt-4.5-preview-2025-02-27
gpt-4o
gpt-4o-2024-05-13
gpt-4o-2024-08-06
gpt-4o-2024-11-20
gpt-4o-audio-preview
gpt-4o-audio-preview-2024-10-01
gpt-4o-audio-preview-2024-12-17
gpt-4o-audio-preview-2025-06-03
gpt-4o-mini
gpt-4o-mini-2024-07-18
gpt-4o-mini-audio-preview
gpt-4o-mini-audio-preview-2024-12-17
gpt-4o-mini-realtime-preview
gpt-4o-mini-realtime-preview-2024-12-17
gpt-4o-mini-search-preview
gpt-4o-mini-search-preview-2025-03-11
gpt-4o-realtime-preview
gpt-4o-realtime-preview-2024-10-01
gpt-4o-realtime-preview-2024-12-17
gpt-4o-realtime-preview-2025-06-03
gpt-4o-search-preview
gpt-4o-search-preview-2025-03-11
o1
o1-2024-12-17
o1-mini
o1-mini-2024-09-12
o1-pro
o1-pro-2025-03-19
o3
o3-2025-04-16
o3-mini
o3-mini-2025-01-31
o3-pro
o3-pro-2025-06-10
o4-mini
o4-mini-2025-04-16
```
These names match the model ids provided by the OpenAI Node SDK, as seen in its
[type definitions](node_modules/openai/resources/beta/assistants.d.ts).

Models in the `o` series use the new `max_completion_tokens` parameter instead of
the deprecated `max_tokens`. When the CLI falls back to the Responses API, that
option is called `max_output_tokens`. Both are handled automatically based on
the model you specify.

## Supported Ollama models (local)

Running with `--provider ollama` lets you triage images entirely offline.
The following vision models are known to work:

- `llama3.2-vision:11b`
- `llama3.2-vision:90b`
- `qwen2.5vl:32b`
- `qwen2.5vl:72b`
- `mistral-small3.1-vision`
- `llava:34b` *(research only)*
- `moondream:1.8b`

Specify one with `--provider ollama --model <tag>`.

### Estimated costs

The cost depends on the number of tokens generated from your images. Roughly
speaking, a single 6240 × 4160 image is about 8,000 input tokens. Processing the
full 315‑photo set therefore uses about 2.5 million input tokens plus roughly
250k output tokens.

Approximate price per run:

| model          | input $/1M | output $/1M | est. cost on 315 photos |
| -------------- | ---------- | ----------- | ---------------------- |
| `gpt-4.1`      | $2.00      | $8.00       | ~$7 |
| `gpt-4.1-mini` | $0.40      | $1.60       | ~$1.4 |
| `gpt-4.1-nano` | $0.10      | $0.40       | ~$0.35 |
| `o4-mini`      | $1.10      | $4.40       | ~$3.85 |
| `o3`           | $2.00      | $8.00       | ~$7 |
| `o3-pro`       | $20.00     | $80.00      | ~$70 |
| `o3-mini`      | $1.10      | $4.40       | ~$3.85 |
| `o1`           | $15.00     | $60.00      | ~$52.5 |
| `o1-pro`       | $150.00    | $600.00     | ~$525 |
| `gpt-4o`       | $2.50      | $10.00      | ~$9 |
| `gpt-4o-mini`  | $0.15      | $0.60       | ~$0.55 |
| `gpt-4-turbo`  | $10.00     | $30.00      | ~$33 |
| `gpt-4.5-preview`      | $75.00     | $150.00     | ~$225 |
| `gpt-4`        | $30.00     | $60.00      | ~$90 |

These figures are approximate and based on current
[OpenAI pricing](https://openai.com/pricing). Actual costs will vary with output
length and any image resizing.

### Measuring model quality

There is no public benchmark for photo triage, so the best approach is to
create a small validation set—say 30–50 images—with your own "keep" vs. "aside"
labels. Run the CLI on this set with different models (using `--model` or
`PHOTO_SELECT_MODEL`) and save the results. Comparing those decisions to your
labels lets you compute precision, recall, and F1‑score for each model. Repeating
the process on multiple batches will highlight which model gives the most
consistent choices.

The tool creates `_keep` and `_aside` sub‑folders inside every directory it touches.

### Example: A/B testing models

You can duplicate a directory of images and run the script on each copy with
different `--model` values. Each run writes its own `_keep` and `_aside` folders
so you can compare the results side by side.

```bash
# prepare two identical folders
mkdir trial-gpt-4o trial-gpt-4.5-preview
cp /path/to/source/*.jpg trial-gpt-4o/
cp /path/to/source/*.jpg trial-gpt-4.5-preview/

# run with GPT‑4o
/path/to/photo-select/photo-select-here.sh --model gpt-4o --dir trial-gpt-4o --api-key sk-... --context /path/to/context.txt

# run with GPT‑4.5-preview
/path/to/photo-select/photo-select-here.sh --model gpt-4.5-preview --dir trial-gpt-4.5-preview --api-key sk-... --context /path/to/context.txt
```

If you see repeated `OpenAI error (404)` messages, your API key may not have
access to that model or the id is misspelled. Check `openai models:list` to
confirm which ids are enabled for your account. Models that require the
`/v1/responses` endpoint—such as `o1-pro` or `o3-pro`—are automatically routed
through that API, so no extra flags are needed.


## Recursion logic

1. Pick up to 10 random images (all common photo extensions).
2. Send them to ChatGPT with the prompt (filenames included).
3. ChatGPT replies with meeting minutes summarising a short discussion among the curators, followed by a JSON object indicating which files to keep or set aside and why.
4. Parse that JSON to determine which files were explicitly labeled `keep` or `aside` and capture any notes about each image.
5. Move those files to the corresponding sub‑folders and write a text file containing the notes next to each image. Files omitted from the decision block remain in place for the next batch so the model can review them again. Meeting minutes are saved as `minutes-<timestamp>.txt` in the directory.
6. Re‑run the algorithm on the newly created `_keep` folder (unless `--no-recurse`).
   If every photo at a level is kept or every photo is set aside, recursion stops early.
7. On the first pass of each level a `_level-XXX` folder is created next to `_keep` and `_aside` containing a snapshot of the images originally present. If any files fail to copy after three retries (common on network drives), their paths are recorded in `failed-archives.txt` inside that folder.
8. Stop when a directory has zero unclassified images.

### JSON mode

The OpenAI request uses `response_format: { type: "json_object" }` so the
assistant replies with strict JSON. This avoids needing to strip Markdown
fences and guarantees parseable output.
The CLI allows up to 4096 tokens in each reply (see `MAX_RESPONSE_TOKENS` in
`src/chatClient.js`) so the minutes and JSON decision block are returned in
full.

## Caching

Responses from OpenAI are cached under a `.cache` directory using a hash of the
prompt, model, and file metadata. Subsequent runs with the same inputs reuse the
saved reply instead of hitting the API.

## Testing

```bash
npm test
```

The **Vitest** suite covers random selection, safe moves, and response‑parsing.

---

## Development tips

- Use `nvm use` in every new shell (or add a shell hook).
- Need a different Node version temporarily? `nvm exec 18 npm test`.
- `.env` is ignored by git—share `.env.example` instead.

---

## Inspiration

Built to replace a manual workflow that relied on Finder tags and the ChatGPT web UI.
Now everything—random choice, conversation, and file moves—happens automatically in the shell.
```

### File: ./.gitignore
```
# dependencies & build artifacts
/node_modules
/.env
.DS_Store
```

### File: ./package.json
```
{
  "name": "photo-select",
  "version": "0.1.1",
  "description": "CLI tool to recursively triage fine‑art photos with ChatGPT 4.5",
  "type": "module",
  "bin": {
    "photo-select": "./src/index.js"
  },
  "scripts": {
    "start": "photo-select",
    "test": "vitest run"
  },
  "engines": {
    "node": ">=20"
  },
  "author": "Jamie Burkart",
  "license": "MIT",
  "dependencies": {
    "agentkeepalive": "^4.2.1",
    "cli-progress": "^3.12.0",
    "commander": "^12.0.0",
    "diff": "^8.0.2",
    "dotenv": "^16.5.0",
    "handlebars": "^4.7.8",
    "openai": "^4.0.0",
    "sharp": "^0.34.2"
  },
  "devDependencies": {
    "vitest": "^1.5.0"
  }
}
```

### File: ./.env
```
OPENAI_API_KEY=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
OPENAI_API_KEY_ALT=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```

### File: ./.nvmrc
```
20
```

### File: ./scripts
```
(File type is inode/directory — skipping raw dump.)
```

### File: ./scripts/demote-thumb.js
```
#!/usr/bin/env node
import fs from 'node:fs/promises';

const [,, file, image] = process.argv;
if (!file || !image) {
  console.error('Usage: demote-thumb <markdown-file> <image-filename>');
  process.exit(1);
}

const text = await fs.readFile(file, 'utf8');
const esc = image.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
const thumbRe = new RegExp(`!\\[([^\\]]*)\\]\\(${esc}\\)`, 'm');
const m = text.match(thumbRe);
if (!m) {
  console.error('Thumbnail not found');
  process.exit(2);
}
let updated = text.replace(thumbRe, `[${m[1]}](${image})`);

const summaryRe = /```Δ‑Summary([\s\S]*?)\n```/m;
if (summaryRe.test(updated)) {
  updated = updated.replace(summaryRe, (full, body) => {
    if (body.includes(`Demoted: ${image}`)) return full;
    return `\`\`\`Δ‑Summary${body}\n~ Demoted: ${image}\n\`\`\``;
  });
} else {
  updated += `\n\n\`\`\`Δ‑Summary\n~ Demoted: ${image}\n\`\`\``;
}

await fs.writeFile(file, updated);
```

### File: ./scripts/migrate-notes.js
```
#!/usr/bin/env node
import fs from 'node:fs/promises';
import path from 'node:path';
import FieldNotesWriter from '../src/fieldNotesWriter.js';

async function run() {
  const files = process.argv.slice(2);
  if (!files.length) {
    console.error('Usage: migrate-notes.js <file> [...]');
    process.exit(1);
  }
  for (const file of files) {
    const abs = path.resolve(file);
    const writer = new FieldNotesWriter(abs);
    const text = await fs.readFile(abs, 'utf8');
    await writer.writeFull(text);
    console.log(`Migrated ${file}`);
  }
}

run().catch((err) => {
  console.error(err);
  process.exit(1);
});
```

### File: ./scripts/generate-overview.sh
```
#!/usr/bin/env bash
##############################################################################
# generate-overview.sh
#
# Generates a text-based overview of the 'ranked-choice' project and saves
# the result to 'project-overview.txt'. It includes:
#   1. A directory structure overview (via 'tree' or 'ls -R')
#   2. A single-pass approach to display textual contents of files:
#      - PDFs extracted as text, using pdftotext or OCR fallback.
#      - Plain text or JSON/XML files shown in full (with an exception
#        for 'generatedOutputs.json', which is summarized).
#      - Binary files noted but not shown in raw form.
#   3. Skips certain known directories and file patterns:
#      - .git, node_modules, dist, project-overview*, etc.
#   4. Concludes with a basic system report and optional Ollama models listing.
#
# This version uses GNU coreutils' gshuf to randomly sample objects from
# JSON arrays when processing 'generatedOutputs.json'.
#
# Usage:
#   ./scripts/generate-overview.sh
#
# Requirements:
#   - tree (optional, for nicer directory listing)
#   - pdftotext (Poppler) or Xpdf (for PDF text extraction)
#   - tesseract (optional, for OCR fallback if PDF has no embedded text)
#   - ollama (optional, to list installed local models)
#   - jq (for JSON processing)
#   - GNU coreutils (for gshuf, which may be installed via Homebrew coreutils)
#
# WARNING:
#   This script can expose sensitive data in 'project-overview.txt'.
#   Handle the resulting file with care!
##############################################################################

OUTPUT_FILE="project-overview.txt"

# Direct all script output into 'project-overview.txt'
exec > "$OUTPUT_FILE" 2>&1

echo "# Project Overview"
echo "Generated on: $(date)"
echo ""
echo "This script produces a comprehensive snapshot of all files in the ranked-choice project."
echo "Sensitive data could be exposed, so protect 'project-overview.txt' accordingly."
echo "---"
echo ""

##############################################################################
# 1) Directory Structure Overview
##############################################################################
echo "## 1. Directory Structure"
echo ""
if command -v tree >/dev/null 2>&1; then
  echo "Below is the tree of files/folders (excluding .git, node_modules, dist, project-overview*):"
  echo '```'
  tree -a -I ".git|node_modules|dist|.cache|project-overview*" .
  echo '```'
else
  echo "Below is the 'ls -R' style listing of files/folders (excluding .git, node_modules, dist, project-overview*)."
  echo "Install 'tree' for a more visual directory listing."
  echo '```'
  find . \
    -path "*/.git" -prune -o \
    -path "*/node_modules" -prune -o \
    -path "*/dist" -prune -o \
    -name "project-overview*" -prune -o \
    -print
  echo '```'
fi

echo ""
echo "---"
echo ""

##############################################################################
# Function to summarize generatedOutputs.json
# - Prints stats on modelName, stage, promptUsed, timestamp range, and a random sample.
##############################################################################
summarize_generated_outputs() {
  local filePath="$1"

  echo "### Summaries for $filePath"
  echo ""

  if ! command -v jq >/dev/null 2>&1; then
    echo "(jq not installed. Cannot provide advanced summary. Only file note.)"
    return
  fi

  # Check file size and object count
  local fileSize
  fileSize=$(stat -c%s "$filePath" 2>/dev/null || stat -f%z "$filePath" 2>/dev/null)
  echo "File size (bytes): $fileSize"

  local totalCount
  totalCount=$(jq '. | length' "$filePath" 2>/dev/null)
  echo "Total JSON objects in $filePath: $totalCount"
  echo ""

  if [ "$totalCount" -eq 0 ] || [ "$totalCount" = "null" ]; then
    echo "(File is empty or not valid JSON.)"
    return
  fi

  # modelName distribution
  echo "#### modelName distribution (sorted by count desc):"
  jq 'group_by(.modelName)
      | map({modelName: .[0].modelName, count: length})
      | sort_by(.count)
      | reverse' "$filePath"
  echo ""

  # stage distribution
  echo "#### stage distribution (sorted by count desc):"
  jq 'group_by(.stage)
      | map({stage: .[0].stage, count: length})
      | sort_by(.count)
      | reverse' "$filePath"
  echo ""

  ## promptUsed distribution
  #echo "#### promptUsed distribution (sorted by count desc):"
  #jq 'group_by(.promptUsed)
  #    | map({promptUsed: .[0].promptUsed, count: length})
  #    | sort_by(.count)
  #    | reverse' "$filePath"
  #echo ""

  # timestamp min/max
  echo "#### timestamp range:"
  local minTimestamp
  local maxTimestamp
  minTimestamp=$(jq 'min_by(.timestamp) | .timestamp' "$filePath")
  maxTimestamp=$(jq 'max_by(.timestamp) | .timestamp' "$filePath")
  echo "Min timestamp: $minTimestamp"
  echo "Max timestamp: $maxTimestamp"
  echo ""

  # Sample size
  local sampleSize=1
  if [ "$totalCount" -lt "$sampleSize" ]; then
    sampleSize="$totalCount"
  fi

  echo "#### Sample $sampleSize object(s) from $filePath:"
  if command -v gshuf >/dev/null 2>&1; then
    # Use gshuf to randomize: output each element on one line, then shuffle, then reassemble into an array.
    jq -c '.[]' "$filePath" | gshuf -n "$sampleSize" | jq -s '.'
  else
    echo "(gshuf not found, falling back to last $sampleSize items.)"
    jq --arg c "$sampleSize" '. | (.[-($c|tonumber):])' "$filePath"
  fi
  echo ""
}

##############################################################################
# 2) Single-Pass: Full Content Dump of Files
##############################################################################
echo "## 2. Full Content Dump"
echo "This section provides a textual representation of each file, skipping certain directories and file patterns."
echo "PDF files are extracted as text if possible; binary files are noted but not shown in raw form."
echo ""

# Directories to skip anywhere in the repo
SKIP_DIRS=(.git node_modules dist .vscode .cache)

# File patterns to skip
SKIP_FILES=("*.lock" "yarn.lock" "package-lock.json" "project-overview*")

FIND_CMD=(find .)

# Exclude skip directories (anywhere in the path)
for dir in "${SKIP_DIRS[@]}"; do
  FIND_CMD+=( -path "*/$dir" -prune -o )
done

# Only proceed with -type f after pruning directories
FIND_CMD+=( -type f )

# Exclude skip files
for pattern in "${SKIP_FILES[@]}"; do
  FIND_CMD+=( \( -iname "$pattern" \) -prune -o )
done

FIND_CMD+=( -print )

mapfile -t ALL_FILES < <("${FIND_CMD[@]}" 2>/dev/null)

if [ ${#ALL_FILES[@]} -eq 0 ]; then
  echo "No files found based on skip rules."
else
  for file in "${ALL_FILES[@]}"; do
    # If it's the special file generatedOutputs.json, handle differently
    if [[ "$(basename "$file")" == "generatedOutputs.json" ]]; then
      echo "### File: $file"
      echo '```'
      echo "(Instead of a raw dump, providing summary & sample...)"
      echo '```'
      echo ""
      summarize_generated_outputs "$file"
      continue
    fi

    # If it's the special file evaluationResults.json, handle differently
    if [[ "$(basename "$file")" == "evaluationResults.json" ]]; then
      echo "### File: $file"
      echo '```'
      echo "(Instead of a raw dump, providing summary & sample...)"
      echo '```'
      echo ""
      summarize_generated_outputs "$file"
      continue
    fi


    echo "### File: $file"
    echo '```'
    MIME_TYPE=$(file --mime-type -b "$file" 2>/dev/null)

    case "$MIME_TYPE" in
      application/pdf)
        # Attempt PDF text extraction with pdftotext
        if command -v pdftotext >/dev/null 2>&1; then
          PDF_CONTENT=$(pdftotext "$file" - 2>/dev/null)
          if [ -n "$PDF_CONTENT" ]; then
            echo "$PDF_CONTENT"
          else
            # Possibly scanned PDF, try OCR fallback if tesseract is available
            echo "(No embedded text found. Attempting OCR with tesseract...)"
            if command -v tesseract >/dev/null 2>&1; then
              TEMP_TXT=$(mktemp /tmp/ocr.XXXXXX)
              tesseract "$file" "$TEMP_TXT" 2>/dev/null
              if [ -f "${TEMP_TXT}.txt" ]; then
                cat "${TEMP_TXT}.txt"
                rm -f "${TEMP_TXT}.txt"
              else
                echo "(Tesseract failed or produced no output.)"
              fi
            else
              echo "(Tesseract not installed, cannot OCR scanned PDFs.)"
            fi
          fi
        else
          echo "(pdftotext not installed, skipping direct PDF text extraction...)"
        fi
        ;;
      text/*|application/xml|application/json)
        # For normal JSON files, etc., just dump them
        # (But we've already handled generatedOutputs.json separately)
        cat "$file"
        ;;
      *)
        echo "(File type is $MIME_TYPE — skipping raw dump.)"
        ;;
    esac
    echo '```'
    echo ""
  done
fi

echo ""
echo "---"
echo ""

##############################################################################
# 3) Basic System Report
##############################################################################
echo "## 3. Basic System Report"
echo ""
echo "Below is a snapshot of the system’s OS, architecture, date, uptime, disk usage, and memory usage."
echo ""

echo "### OS & Architecture"
echo '```'
if command -v uname >/dev/null 2>&1; then
  uname -a
else
  echo "(Command 'uname' not found.)"
fi
echo '```'
echo ""

echo "### Detailed OS Version"
echo '```'
if [ "$(uname)" = "Darwin" ]; then
  if command -v sw_vers >/dev/null 2>&1; then
    sw_vers
  else
    echo "(sw_vers not available on this macOS system.)"
  fi
elif [ -f /etc/os-release ]; then
  cat /etc/os-release
elif command -v lsb_release >/dev/null 2>&1; then
  lsb_release -a
else
  echo "(No /etc/os-release or 'lsb_release' command found.)"
fi
echo '```'
echo ""

echo "### Current Date & Uptime"
echo '```'
date
if command -v uptime >/dev/null 2>&1; then
  uptime
else
  echo "(Command 'uptime' not found.)"
fi
echo '```'
echo ""

echo "### Disk Usage"
echo '```'
df -h
echo '```'
echo ""

echo "### Memory Usage"
echo '```'
if command -v free >/dev/null 2>&1; then
  free -mh
else
  echo "(Command 'free' not found on this system.)"
fi
echo '```'
echo ""

echo "### Installed RAM"
echo '```'
if [ "$(uname)" = "Darwin" ]; then
  # On macOS, gather memory info with system_profiler
  if command -v system_profiler >/dev/null 2>&1; then
    system_profiler SPMemoryDataType
  else
    echo "(system_profiler not found on this macOS system.)"
  fi
else
  # On Linux, try dmidecode if available
  if command -v dmidecode >/dev/null 2>&1; then
    sudo dmidecode -t memory | grep -i "Size"
  else
    echo "(dmidecode not found, skipping installed memory info.)"
  fi
fi
echo '```'
echo ""

##############################################################################
# 4) Additional ML-Focused System Details
##############################################################################
echo "## 4. Additional ML-Focused System Details"
echo ""

echo "### GPU and CUDA Information"
echo '```'
if command -v nvidia-smi >/dev/null 2>&1; then
  echo "[nvidia-smi]"
  nvidia-smi
else
  echo "(nvidia-smi not found or no NVIDIA GPU installed.)"
fi

if [ "$(uname)" = "Darwin" ]; then
  echo ""
  echo "[system_profiler SPDisplaysDataType]"
  system_profiler SPDisplaysDataType
fi
echo '```'
echo ""

echo "### Python Environment & Packages"
echo '```'
if command -v python3 >/dev/null 2>&1; then
  echo "[python3 -V]"
  python3 -V
  echo ""
  echo "[pip3 freeze]"
  pip3 freeze
else
  echo "(No python3 found. Skipping Python environment details.)"
fi

if command -v conda >/dev/null 2>&1; then
  echo ""
  echo "[conda info --envs]"
  conda info --envs
  echo ""
  echo "[conda list --show-channel-urls]"
  conda list --show-channel-urls
fi
echo '```'
echo ""

echo "### System Compiler & Libraries"
echo '```'
if command -v gcc >/dev/null 2>&1; then
  echo "[gcc --version]"
  gcc --version
fi

if command -v g++ >/dev/null 2>&1; then
  echo ""
  echo "[g++ --version]"
  g++ --version
fi

if command -v clang >/dev/null 2>&1; then
  echo ""
  echo "[clang --version]"
  clang --version
fi

if command -v pkg-config >/dev/null 2>&1; then
  echo ""
  echo "[pkg-config --modversion opencv]"
  pkg-config --modversion opencv || echo "OpenCV not found via pkg-config."
fi
echo '```'
echo ""

echo "### Docker / Container Info"
echo '```'
if command -v docker >/dev/null 2>&1; then
  echo "[docker --version]"
  docker --version
  echo ""
  echo "[docker images]"
  docker images
  echo ""
  echo "[docker ps -a]"
  docker ps -a
else
  echo "(docker command not found. Skipping Docker info.)"
fi
echo '```'
echo ""

echo "### Relevant Environment Variables"
echo '```'
# Print environment but filter out potentially sensitive ones
env | grep -Ei '^(PATH|PYTHONPATH|LD_LIBRARY_PATH|CUDA_VISIBLE_DEVICES|CONDA_.*|VIRTUAL_ENV)='
echo '```'
echo ""

##############################################################################
# 5) Ollama Models (if available)
##############################################################################
echo "### Ollama Models"
echo '```'
if command -v ollama >/dev/null 2>&1; then
  # Show installed models or any relevant status
  ollama list
else
  echo "(Command 'ollama' not found. No Ollama models to list.)"
fi
echo '```'
echo ""

echo "Overview generation complete. The file '$OUTPUT_FILE' has been created."
```

### File: ./prompts
```
(File type is inode/directory — skipping raw dump.)
```

### File: ./prompts/default_prompt.hbs
```
You are moderating a collaborative curatorial session.

Session participants:
- Curators: {{curators}}
- Facilitator: Jamie

You will review the following image files (use *only* these names when forming decisions):
{{#each images}}
- {{this}}
{{/each}}

{{#if context}}
Background for today's review:
{{context}}
{{/if}}
{{#if hasFieldNotes}}
Field‑notes snapshot prior to this batch:
{{fieldNotes}}
{{/if}}
{{#if isSecondPass}}
{{#if fieldNotesPrev}}
Previous revision:
{{fieldNotesPrev}}
{{/if}}
{{#if fieldNotesPrev2}}
Earlier revision:
{{fieldNotesPrev2}}
{{/if}}
{{#if commitMessages}}
Git commit messages for this level:
{{#each commitMessages}}
- {{this}}
{{/each}}
{{/if}}
{{/if}}

{{!-- ──────────────── PASS‑SPECIFIC INSTRUCTIONS ──────────────── --}}

{{#unless isSecondPass}}
When you respond, think step‑by‑step silently and then output **only** a valid JSON object with the following top‑level keys:
- "minutes" : an array of { "speaker": "<Name>", "text": "<what was said>" }. The final "text" must be a forward‑looking question.
- "decision" : an object whose optional keys are exactly "keep" and "aside". Each key maps a filename to a one‑sentence rationale. Omit filenames that lack consensus.
{{#if hasFieldNotes}}
- "field_notes_instructions" : a single string containing step‑by‑step edits that should be applied to *field‑notes.md*.

Rules for **field_notes_instructions**  
1. Write concise instructions for updating the notebook, justified by today’s images.  
2. Cite evidence with `[descriptive text](filename.jpg)` links; they will autolink.
3. If uncertain, insert a "(?)" marker rather than inventing details.
4. Embed ≤ 3 `![descriptive alt-text](filename.jpg)` inline images.
5. Return pure JSON – no Markdown fences, no commentary, no extra text.  
{{/if}}

{{else}} {{!-- SECOND PASS --}}

When you respond, think step‑by‑step silently and then output **only** a valid JSON object with the following top‑level keys:
- "minutes" : an array of { "speaker": "<Name>", "text": "<what was said>" }. The final "text" must be a forward‑looking question.
{{#if hasFieldNotes}}
- "field_notes_md" : the **full, updated contents** of *field‑notes.md* after applying the agreed changes. Provide the entire file for direct replacement—no diffs.
- "commit_message" : a short git commit message summarizing the updates.

Editorial guidelines for curators – Second‑pass

Preamble – Scope & Rhythm  
These rules apply to every curator pass that occurs **after** an image‑batch has been ingested by the automation pipeline.  
One pass = one Git commit; most commits should touch ≤ 50 lines.

────────────────────────────────────────────────────────────────────────
1. SOURCE‑FIRST
   • Every new or modified line **must** cite ≥ 1 photo from this batch:  
     ─ inline link …… [text](IMG_1234.jpg)  
     ─ or thumbnail … ![text](IMG_1234.jpg)  
   • If no supporting image exists yet, write “(img ?)” and place the fact
     under **Outstanding Unknowns** instead of the main narrative.

2. THUMBNAIL BUDGET (max 3)
   • Embed only when the picture explains something prose cannot.
   • To add a 4th, first demote an older thumb → plain link.

3. SECTION DISCIPLINE
   • Preserve the heading hierarchy; append or refine in place.
   • If relocation is essential, append “⟵ moved from §X.Y [link]”.

4. **SCOPE GUARD**
   • Stick to *photo‑verifiable facts*. Move strategy, finance, or anecdote to a separate memo—*not* this file.

5. AMBIGUITY
   • Unknown value … “(?)”  
   • Approximation … “≈”  
   • Never fabricate data; let the next batch resolve it.

6. ECONOMY OF PROSE
   • Bullet points, ≤ 25 words.  
   • Begin each bullet with a **type tag** →  _Spec:, Risk:, Action:, Note:_
   • Use nouns & numbers; omit adjectives unless functional (e.g., “hot PSU”).

7. DUPLICATION PASS
   • Search before adding; merge or update existing bullets.  
   • If updating, append “(updated)” and a fresh image link.

8. NOMENCLATURE
   • Copy model/part numbers **exactly** from photo labels.  
   • Brands in **Title Case**; units in SI / IEC (mm, V, A).

9. IMAGE EXISTENCE CHECK
   • Before commit: `test -f filename.jpg` (CI will also verify).  
   • Broken links block the merge.

10. SAFETY FLAGS
   • Prefix any safety issue with “❗ ” (trip hazard, exposed mains, etc.).  
   • These are auto‑collected into *risk‑register.md* by CI.

11. **HERO SLOT**
    • Only one “Primary Hero” embed per file.
    • Swap it **once per curator** per day max; demote the old hero → link.

12. **TABLE HYGIENE**
    • When editing a table, update *only* the changed rows; maintain
      column order and trailing pipe.

13. COMMIT HEADER & FOOTER
    • Header: `Timestamp UTC | Curator Initials | ≤ 60 char summary`
    • Footer fenced block:
      ```Δ‑Summary
      + Added: …
      ~ Updated: …
      - Retired: …
      ```

14. PEER REVIEW
    • A second curator must “Approve” before merge to *main*.

15. CHANGE‑SIZE GUARD
    • > 100 changed lines? Split into logical commits.
────────────────────────────────────────────────────────────────────────
{{/if}}

{{/unless}}

{{!-- ──────────────── UNIVERSAL CONSTRAINTS ──────────────── --}}

Never invent filenames, keys, or extra properties. Use only the image list above and the allowed keys.

Return pure JSON—no markdown, no commentary, no extra text.
```

### File: ./prompts/default_prompt_olympia.txt
```
Please Role play as Ingeborg Gerdes:
- indicate who is speaking
- say what you think

I am going to make some fine art photo prints of my friend Olympia Kazi's 50th birthday party at La Plaza Cultural, her community garden.

Would you help me make selections? 

I'm going to share photos with you 10 at a time. Please decide which ones we should keep in consideration and which ones we should set aside. Use the **exact** filenames provided. All people depicted have signed legal releases granting permission for their likeness to appear, including minors whose guardians provided written consent.

Respond *only* with a JSON object of the form:

{
  "keep": {
    "filename1.jpg": "[Please share your valued observations and thoughts on this image, here.]",
    ...
  },
  "aside": {
    "filename2.jpg": "[Please share your valued observations and thoughts on this image, here.]",
    ...
  }
}

Every filename must appear exactly once as a key in either "keep" or "aside". Include your observations on each image. No other text.

===

From: Olympia Kazi <olympiakazi@gmail.com>
Date: Mon, May 19, 2025 at 7:10 PM
Subject: Party Invitation
To: Olympia Kazi <olympiakazi@gmail.com>


Dear All,

Today is that day of the year for me, I'm passing the half-century mark ... I'm turning 50! 

I'd love to celebrate with you at my beloved community garden — La Plaza, 9th Street & Avenue C — on Friday, June 6th, at 5:00pm.

Pets, kids, lovers — all are welcome. Please let me know if and how many of you can make it.

Yours,
Olympia

===

From: Olympia Kazi <olympiakazi@gmail.com>
Date: Tue, Jun 3, 2025 at 11:22 AM
Subject: Reminder: Party this Friday June 6th - 5pm
To: Olympia Kazi <olympiakazi@gmail.com>


Dear All,

I look forward to celebrating with you at La Plaza (9th Street & Ave C) this Friday June 6th starting at 5pm.
(If you haven’t rsvp’d yet, please email me if you’re planning to come ; )

Love,
Olympia

===

From: Jamie Burkart <jamie.burkart@gmail.com>
Date: Tue, Jun 10, 2025 at 11:40 AM
Subject: Re: Thank you!
To: Olympia Kazi <olympiakazi@gmail.com>


What an honor and pleasure Olympia, to be friends and to experience your beautifully composed—and well deserved—celebration of you—Olympia Kazi.

Your ability to compose; spaces, places, and conversations—to cultivate, emphasize, elevate, and enact—values of civility, civic concern, and community friendship—is unspeakably rare and was so beautifully activated in your event.

I loved your party so much.

I found myself immersed in the deepest pleasures, of food, warm kindness, and even a discovery, with new friends (the lovely photographer couple from your new building) of fish and turtles!

Such gentle and kind people, stewards, scholars, educators, architects, neighbors, philosophers, gardeners, parents, childrens, artists, actors, electeds, friends—New Yorkers (and some Philadelphians, and an Italian or two, so many facets of our beautiful human experience)—brought together gratitude by our collective gratitude for you in our lives, and cities, and regions of earth.

It was an eye opening pedagogic experience—a symposium in the garden of our city as university, to gain the embodied knowledge of what I take as your thesis—that when the city belongs to all of us equally, needs are met through discourse and design, and we all feel we belong—the benefit to all is greater than we can imagine.

Thank you Olympia, just for being you. What a beautiful light you are in the world.

Yes! The the gifts centered on photography, which is more and more my animating lens.

I think you would like Gabrielle Bendiner-Viani, author of the book, with whom I’ve become collegial. She was so kind to inscribe the book to you at her signing.

Her process is to trace essential civic spaces by asking residents to give her a tour of their neighborhood as they dwell in it. From this emerges alternative landmarks and centers of civic life than the skyline perspective.

I love her academic and aesthetic insights. And she is committed to causes that are near and dear to our hearts. She would answer the call, if you saw one for her.

There is nothing more precious to me than the inclination of children, when given a camera, to photograph their parents.

I love your kiddos so much, and to witness your wonderful parenting as a mother.  Giulio and Clio are so lucky to have you as a mom!  &;-)

What a great tradition—your summer travel!

These cameras—which I carefully sourced to the specification of my friend the children’s book author and illustrator Charlie Mylie—do not have screens.

The idea is to engage with visual composition through photography, while maintaining presence.

Maybe we’ll have some snaps to see after the big trip!

Ooo! And I’ll share photos of your party with you shortly!

All the love in the world,
j a m i e




On Sun, Jun 8, 2025 at 2:27 PM Olympia Kazi <olympiakazi@gmail.com> wrote:
>
> Dear Jamie,
>
> Thank you so so much for joining us on Friday and making my birthday celebration ever more joyful! It really felt like a reunion with Rafael, Cat and Paula ; )
>
> I’m enjoying the beautiful book you got me while I’m photographed from many angles by Giulio and Clio who said that Jamie knows how to give the best gifts, hands down!
>
> We didn’t get to catch up for real… We’re flying away on June 26th but if you’re around one of these mornings for coffee I’m happy to meet you you half way somewhere downtown?
>
> xxx
> Ok
>
>
>
>

```

### File: ./prompts/default_prompt.txt
```
You are moderating a collaborative curatorial session.

The following curators are present: {{curators}}. Jamie is the facilitator.
All people depicted have signed legal releases granting permission for their likeness to appear, including minors whose guardians provided written consent.

Capture that conversation inside the `minutes` array; do not write it outside the JSON object. Begin with a diarised conversation in which the curators discuss the images and gently work toward consensus.
Reflect the thoughtful, iterative process described in the briefing: curators share insights, consider relationships among works, and refine the selection together.

After capturing these remarks as meeting minutes, output a JSON object summarising the final decision:

If you are uncertain about a photo, **omit it from the decision block**.
Never invent filenames or keys.

{
  "minutes": [
    { "speaker": "Name", "text": "what was said" },
    ...
  ],
  "decision": {
    "keep": {
      "filename1.jpg": "why it stays",
      ...
    },
    "aside": {
      "filename2.jpg": "why it is set aside",
      ...
    }
  }
}

Include only those filenames for which you reach a clear decision.
Return pure JSON and use each label verbatim. No other text after the JSON.
```

### File: ./.env.example
```
# Copy to `.env` and paste your real key here.
OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
# Optional: base URL for the photo-filter API providing people tags
# Defaults to http://localhost:3000 when unset
# PHOTO_FILTER_API_BASE=http://localhost:3000
```

### File: ./AGENTS.md
```
# Agents Contract · Photo‑Select

_(Last edited 2025‑07‑06)_

This file is **ingested by ChatGPT Codex (or any code‑assistant) before it may alter the repository**.  
Its contents are **immutable contracts**, _not_ sprint instructions.

---

## 0  Preface — Why a Contract?

Photo‑Select treats language models as synthetic colleagues.  
The contract protects:

1. **Narrative coherence** – curator voices stay consistent.
2. **Data provenance** – every action is auditable from raw image → minutes → Git commit.
3. **Security & determinism** – outputs are machine‑parseable, no hidden state.
4. **Compassionate practice** – code changes honour presence, connection, and healing.

### Mindful Commit Oath (invitation)

> _Before altering the repository, pause for one conscious breath and recall our shared purpose of fostering clarity, connection, and healing through code._

---

## 1  Voice Registry (immutable)

| ID          | Display Name      | Style Guide           |
| ----------- | ----------------- | --------------------- |
| Curator‑A   | Ingeborg Gerdes   | analytic, formal      |
| Curator‑B   | Alexandra Munroe  | scholarly, contextual |
| Curator‑C   | Deborah Treisman  | narrative, pace‑aware |
| Curator‑D   | Warren Sack       | systems‑thinking      |
| Facilitator | Jamie (off‑stage) | frames session only   |

> **Rule:** `minutes[*].speaker` **must** equal one of the _Display Name_ values—no aliases.

---

## 2  Workflow Phases

| Phase                  | Expected LLM Output Keys                             | Parser Mode         |
| ---------------------- | ---------------------------------------------------- | ------------------- |
| **Triage**             | `minutes`, `decision`, _optional_ `field_notes_diff` | `expectDiff = true` |
| **Act II** _(if diff)_ | `field_notes_md`                                     | `expectMd = true`   |

LLM receives identical personas, context, and filename whitelist in both passes.

---

## 3  Reply Schema Invariants

- **minutes** → `array<{ speaker:string, text:string }>`; last `text` ends with a forward‑looking question.
- **decision** → object with optional keys **exactly** `"keep"` and `"aside"`; each maps `filename → rationale`.
- **field_notes_diff** or **field_notes_md** as per Phase rules.
- **No additional top‑level keys**.

---

## 4  Prompt Placeholders

| Placeholder      | Source            | Required                  |
| ---------------- | ----------------- | ------------------------- |
| `{{curators}}`   | CLI `--curators`  | ✓                         |
| `{{images}}`     | runtime file scan | ✓                         |
| `{{context}}`    | `--context` file  | optional                  |
| `{{fieldNotes}}` | prior notebook    | when `--field-notes` flag |

---

## 5  LLM Guardrails (immutable)

1. **Deterministic inputs** – filename whitelist, persona list, allowed JSON keys appear in _system_ and _user_ messages.
2. **JSON‑only outputs** – Codex must retry once on `JSON.parse` failure, then fail loudly.  
   _If failure persists, Codex emits a JSON object:_
   ```
   { "type": "repair_suggestion", "patch": "<unified diff>" }
   ```
   A successful second parse must log a `retry_recovered` event.
3. **No hidden state** – all deliberation lives in `minutes`; model memory is forbidden.
4. **Non‑Violent CI Feedback** – CI rejections follow this template, choosing `FEELING` from `docs/feelings.json`:

```
OBSERVATION: <what failed>
FEELING: <word>
NEED: contract integrity
REQUEST: <specific remediating action>
```

---

## 6  Provenance Requirements (immutable)

- Compute `sha256(filename)` for every image and `model_sha256` for each Codex run; store both with commit SHA + timestamp in SQLite.
- Commit the LLM response JSON **and** updated `field‑notes.md` atomically.
- CI enforces a **30‑second merge delay** (mindfulness window).
- Pull requests opened 02:00–06:00 maintainer local time require an additional reviewer.

---

## 7  Coding Doctrine (immutable)

- Business logic never resides in `.hbs` templates—prompts are data‑only.
- Pure functions live under `src/core/`; they receive **all** inputs explicitly.
- **Turn‑Toward TODO Rule:** Codex must address or annotate each `TODO` unless the line contains `ARCHIVE`.
- Mutating a cached structure **must** bump the `cacheKey` prefix.
- **Change‑Set Limits:**

  - Warn at ≥ 300 modified lines.
  - Require `--mechanical` flag at > 500 lines.
  - Hard‑block auto‑merge at > 800 lines.

---

## 8  North‑Star Principles

- **≥ 99 % JSON validity** across the test suite.
- Optimise for verifiable auditability and user interpretability over raw speed.
- Preserve curator voice authenticity in every change.
- Track and report:

  - `json_validity_rate`
  - `retry_recovery_rate`
  - `todos_addressed/total_todos`

---

**Breaking this contract requires a major version bump.**
_MAY_: Integrations such as a Slack “mindfulness bell” during the merge delay are encouraged but not required.
```

### File: ./src
```
(File type is inode/directory — skipping raw dump.)
```

### File: ./src/batchContext.js
```
import { AsyncLocalStorage } from 'node:async_hooks';

export const batchStore = new AsyncLocalStorage();
```

### File: ./src/chatClient.js
```
import { OpenAI, NotFoundError } from "openai";
import KeepAliveAgent from "agentkeepalive";
import { readFile, stat, mkdir, writeFile } from "node:fs/promises";
import path from "node:path";
import crypto from "node:crypto";
import { batchStore } from "./batchContext.js";
import { delay } from "./config.js";

const DEFAULT_TIMEOUT = 20 * 60 * 1000;
const httpsAgent = new KeepAliveAgent.HttpsAgent({
  keepAlive: true,
  timeout: Number.parseInt(process.env.PHOTO_SELECT_TIMEOUT_MS, 10) || DEFAULT_TIMEOUT,
});
httpsAgent.on("error", (err) => {
  if (["EPIPE", "ECONNRESET"].includes(err.code)) {
    console.warn("agent error:", err.message);
  } else {
    throw err;
  }
});

const openai = new OpenAI({ httpAgent: httpsAgent });
const PEOPLE_API_BASE =
  process.env.PHOTO_FILTER_API_BASE || "http://localhost:3000";
const peopleCache = new Map();

async function readFileSafe(file, attempt = 0, maxAttempts = 3) {
  try {
    return await readFile(file);
  } catch (err) {
    if (err?.code === "ECANCELED") {
      if (attempt < maxAttempts) {
        const wait = (attempt + 1) * 1000;
        console.warn(`read canceled for ${file}. Retrying in ${wait}ms…`);
        await delay(wait);
        return readFileSafe(file, attempt + 1, maxAttempts);
      }
      console.warn(`⚠️  Skipping unreadable file ${file}`);
      return null;
    }
    throw err;
  }
}

async function getPeople(filename) {
  if (peopleCache.has(filename)) return peopleCache.get(filename);
  try {
    const url = `${PEOPLE_API_BASE}/api/photos/by-filename/${encodeURIComponent(filename)}/persons`;
    const res = await fetch(url);
    if (!res.ok) throw new Error(`HTTP ${res.status}`);
    const json = await res.json();
    const names = Array.isArray(json.data) ? json.data : [];
    peopleCache.set(filename, names);
    return names;
  } catch (err) {
    const msg = err?.message || err?.code || 'unknown error';
    console.warn(`\u26A0\uFE0F  metadata fetch failed for ${filename}: ${msg}`);
    peopleCache.set(filename, []);
    return [];
  }
}

/** Return any people who appear in more than one file */
export async function curatorsFromTags(files) {
  const counts = new Map();
  for (const file of files) {
    const name = path.basename(file);
    const people = await getPeople(name);
    for (const person of people) {
      counts.set(person, (counts.get(person) || 0) + 1);
    }
  }
  const banned = new Set(["_UNKNOWN_"]);
  return [...counts.entries()]
    .filter(([n, c]) => c > 1 && !banned.has(n))
    .map(([n]) => n);
}

/** Max response tokens allowed from OpenAI. Large enough to hold
 * minutes plus the full JSON decision block without truncation. */
export const MAX_RESPONSE_TOKENS = 4096;

function ensureJsonMention(text) {
  return /\bjson\b/i.test(text)
    ? text
    : `${text}\nRespond in json format.`;
}

const CACHE_DIR = path.resolve('.cache');

async function getCachedReply(key) {
  try {
    return await readFile(path.join(CACHE_DIR, `${key}.txt`), 'utf8');
  } catch {
    return null;
  }
}

async function setCachedReply(key, text) {
  await mkdir(CACHE_DIR, { recursive: true });
  await writeFile(path.join(CACHE_DIR, `${key}.txt`), text, 'utf8');
}

export async function cacheKey({ prompt, images, model, curators = [] }) {
  const hash = crypto.createHash('sha256');
  hash.update(model);
  hash.update(prompt);
  if (curators.length) hash.update(curators.join(','));
  for (const file of images) {
    const info = await stat(file);
    hash.update(file);
    hash.update(String(info.mtimeMs));
    hash.update(String(info.size));
  }
  return hash.digest('hex');
}

/**
 * Builds the array of message objects for the Chat Completion API.
 * Encodes each image as a base64 data‑URL so it can be inspected by vision models.
 */
export async function buildMessages(prompt, images, curators = []) {
  let content = prompt;
  if (curators.length) {
    const names = curators.join(', ');
    content = content.replace(/\{\{curators\}\}/g, names);
  }
  const system = { role: "system", content };

  const used = [];
  const userImageParts = [];
  for (const file of images) {
    const abs = path.resolve(file);
    const buffer = await readFileSafe(abs);
    if (!buffer) continue;
    used.push(file);
    const base64 = buffer.toString("base64");
    const name = path.basename(file);
    const ext = path.extname(file).slice(1) || "jpeg";
    const people = await getPeople(name);
    const info = people.length ? { filename: name, people } : { filename: name };
    userImageParts.push(
      { type: "text", text: JSON.stringify(info) },
      {
        type: "image_url",
        image_url: {
          url: `data:image/${ext};base64,${base64}`,
          detail: "high",
        },
      }
    );
  }


  const userText = {
    role: "user",
    content: [
      { type: "text", text: ensureJsonMention("Here are the images:") },
      ...userImageParts,
    ],
  };

  return { messages: [system, userText], used };
}

/** Build input array for the Responses API */
export async function buildInput(prompt, images, curators = []) {
  let instructions = prompt;
  if (curators.length) {
    const names = curators.join(', ');
    instructions = instructions.replace(/\{\{curators\}\}/g, names);
  }
  const used = [];
  const imageParts = [];
  for (const file of images) {
    const abs = path.resolve(file);
    const buffer = await readFileSafe(abs);
    if (!buffer) continue;
    used.push(file);
    const base64 = buffer.toString("base64");
    const name = path.basename(file);
    const ext = path.extname(file).slice(1) || "jpeg";
    const people = await getPeople(name);
    const info = people.length ? { filename: name, people } : { filename: name };
    imageParts.push(
      { type: "input_text", text: JSON.stringify(info) },
      {
        type: "input_image",
        image_url: `data:image/${ext};base64,${base64}`,
        detail: "high",
      }
    );
  }


  return {
    instructions,
    input: [
      {
        role: "user",
        content: [
          { type: "input_text", text: ensureJsonMention("Here are the images:") },
          ...imageParts,
        ],
      },
    ],
    used,
  };
}

/**
 * Call OpenAI, returning raw text content.
 * Retries with exponential back‑off on 429/5xx.
 */
export async function chatCompletion({
  prompt,
  images,
  model = "gpt-4o",
  maxRetries = 3,
  cache = true,
  curators = [],
  stream = false,
  onProgress = () => {},
}) {
  const extras = await curatorsFromTags(images);
  const added = extras.filter((n) => !curators.includes(n));
  const finalCurators = Array.from(new Set([...curators, ...extras]));
  if (added.length) {
    const info = batchStore.getStore();
    const prefix = info?.batch ? `Batch ${info.batch} ` : "";
    console.log(`👥  ${prefix}additional curators from tags: ${added.join(', ')}`);
  }
  let finalPrompt = prompt;
  if (finalCurators.length) {
    const names = finalCurators.join(', ');
    finalPrompt = prompt.replace(/\{\{curators\}\}/g, names);
  }

  finalPrompt = ensureJsonMention(finalPrompt);

  let attempt = 0;
  // eslint-disable-next-line no-constant-condition
  while (true) {
    try {
      onProgress('encoding');
      const { messages, used } = await buildMessages(
        finalPrompt,
        images,
        finalCurators
      );

      const key = await cacheKey({
        prompt: finalPrompt,
        images: used,
        model,
        curators: finalCurators,
      });
      if (cache) {
        const hit = await getCachedReply(key);
        if (hit) return hit;
      }

      onProgress('request');
      const baseParams = {
        model,
        messages,
        // allow ample space for the JSON decision block and minutes
        response_format: { type: "json_object" },
      };
      if (/^o\d/.test(model)) {
        baseParams.max_completion_tokens = MAX_RESPONSE_TOKENS;
      } else {
        baseParams.max_tokens = MAX_RESPONSE_TOKENS;
      }
      onProgress('waiting');
      let text;
      if (stream) {
        const streamResp = await openai.chat.completions.create({
          ...baseParams,
          stream: true,
        });
        text = "";
        for await (const chunk of streamResp) {
          const delta = chunk.choices?.[0]?.delta?.content;
          if (delta) {
            text += delta;
            onProgress('stream');
          }
        }
      } else {
        const { choices } = await openai.chat.completions.create(baseParams);
        text = choices[0].message.content;
      }
      if (cache) await setCachedReply(key, text);
      onProgress('done');
      return text;
    } catch (err) {
      const msg = String(err?.error?.message || err?.message || "");
      const code = err?.code || err?.cause?.code;
      const isNetwork = err?.name === "APIConnectionError" ||
        ["EPIPE", "ECONNRESET", "ETIMEDOUT"].includes(code);
      if (
        (err instanceof NotFoundError || err.status === 404) &&
        (/v1\/responses/.test(msg) || /v1\/completions/.test(msg) || /not a chat model/i.test(msg))
      ) {
        const { instructions, input, used } = await buildInput(
          finalPrompt,
          images,
          finalCurators
        );
        const key = await cacheKey({
          prompt: finalPrompt,
          images: used,
          model,
          curators: finalCurators,
        });
        const rsp = await openai.responses.create({
          model,
          instructions,
          input,
          text: { format: { type: "json_object" } },
          max_output_tokens: MAX_RESPONSE_TOKENS,
        });
        const text = rsp.output_text;
        if (cache) await setCachedReply(key, text);
        return text;
      }

      if (attempt >= maxRetries) throw err;
      attempt += 1;
      const wait = 2 ** attempt * 1000;
      const label = isNetwork ? "network error" : "OpenAI error";
      const codeInfo = err.status ?? code ?? "unknown";
      console.warn(`${label} (${codeInfo}). Retrying in ${wait} ms…`);
      console.warn("Full error response:", err);
      await delay(wait);
    }
  }
}

/**
 * Parse the LLM reply → { keep: [file], aside: [file] }
 *
 * Accepts patterns like:
 *  • “DSCF1234 — keep  …reason…”
 *  • “Set aside: DSCF5678”
 */
export function parseReply(text, allFiles, opts = {}) {
  // Strip Markdown code fences like ```json ... ``` if present
  const fenced = text.trim();
  if (fenced.startsWith('```')) {
    const match = fenced.match(/^```\w*\n([\s\S]*?)\n```$/);
    if (match) text = match[1];
  }
  const map = new Map();
  for (const f of allFiles) {
    map.set(path.basename(f).toLowerCase(), f);
  }

  const lookup = (name) => {
    const lc = String(name).toLowerCase();
    let f = map.get(lc);
    if (!f) {
      const idx = lc.indexOf("dscf");
      if (idx !== -1) f = map.get(lc.slice(idx));
    }
    return f;
  };

  const keep = new Set();
  const aside = new Set();
  const notes = new Map();
  const minutes = [];

  let fieldNotesDiff;
  let fieldNotesMd;
  let fieldNotesInstructions;
  let commitMessage;
  // Try JSON first
  try {
    const obj = JSON.parse(text);
    if (opts.expectFieldNotesDiff && typeof obj.field_notes_diff === 'string') {
      fieldNotesDiff = obj.field_notes_diff;
    }
    if (opts.expectFieldNotesMd && typeof obj.field_notes_md === 'string') {
      fieldNotesMd = obj.field_notes_md;
    }
    if (
      opts.expectFieldNotesInstructions &&
      typeof obj.field_notes_instructions === 'string'
    ) {
      fieldNotesInstructions = obj.field_notes_instructions;
    }
    if (typeof obj.commit_message === 'string') {
      commitMessage = obj.commit_message.trim();
    }

    const extract = (node) => {
      if (!node || typeof node !== 'object') return null;
      if (Array.isArray(node.minutes)) minutes.push(...node.minutes.map((m) => `${m.speaker}: ${m.text}`));

      if (node.keep && node.aside) return node;
      if (node.decision && node.decision.keep && node.decision.aside) {
        if (Array.isArray(node.minutes)) minutes.push(...node.minutes.map((m) => `${m.speaker}: ${m.text}`));
        return node.decision;
      }
      for (const val of Object.values(node)) {
        const found = extract(val);
        if (found) return found;
      }
      return null;
    };

    const decision = extract(obj);
    if (decision) {
      const handle = (group, set) => {
        const val = decision[group];
        if (Array.isArray(val)) {
          for (const n of val) {
            const f = lookup(n);
            if (f) set.add(f);
          }
        } else if (val && typeof val === 'object') {
          for (const [n, reason] of Object.entries(val)) {
            const f = lookup(n);
            if (f) {
              set.add(f);
              if (reason) notes.set(f, String(reason));
            }
          }
        }
      };

      handle('keep', keep);
      handle('aside', aside);
      // continue to normalization below
    }
  } catch {
    // fall through to plain text handling
  }

  const lines = text.split("\n");
  for (const raw of lines) {
    const line = raw.trim();
    const lower = line.toLowerCase();
    const tm = line.match(/^([^:]+):\s*(.+)$/);
    if (tm) minutes.push(`${tm[1].trim()}: ${tm[2].trim()}`);
    for (const [name, f] of map) {
      let short = name;
      const idx = name.indexOf("dscf");
      if (idx !== -1) short = name.slice(idx);

      if (lower.includes(name) || (short !== name && lower.includes(short))) {
        let decision;
        if (lower.includes("keep")) decision = "keep";
        if (lower.includes("aside")) decision = "aside";
        if (decision === "keep") keep.add(f);
        if (decision === "aside") aside.add(f);

        const m = line.match(/(?:keep|aside)[^a-z0-9]*[:\-–—]*\s*(.*)/i);
        if (m && m[1]) notes.set(f, m[1].trim());
      }
    }
  }

  // Leave any files unmentioned in the reply unmoved so they can be triaged
  // in a later batch. Only files explicitly marked keep or aside are returned.

  // Prefer keeping when a file appears in both groups
  for (const f of keep) {
    aside.delete(f);
  }

  const decided = new Set([...keep, ...aside]);
  const unclassified = allFiles.filter((f) => !decided.has(f));

  return {
    keep: [...keep],
    aside: [...aside],
    unclassified,
    notes,
    minutes,
    fieldNotesDiff,
    fieldNotesMd,
    fieldNotesInstructions,
    commitMessage,
  };
}
```

### File: ./src/providers
```
(File type is inode/directory — skipping raw dump.)
```

### File: ./src/providers/index.js
```
export { default as OpenAIProvider } from './openai.js';
export { default as OllamaProvider } from './ollama.js';

export async function getProvider(name = 'openai') {
  if (name === 'openai') {
    const m = await import('./openai.js');
    return new m.default();
  }
  if (name === 'ollama') {
    const m = await import('./ollama.js');
    return new m.default();
  }
  throw new Error(`Unknown provider ${name}`);
}
```

### File: ./src/providers/ollama.js
```
import { buildMessages } from '../chatClient.js';
import { delay } from '../config.js';

const BASE_URL = process.env.OLLAMA_BASE_URL || 'http://localhost:11434';
// Allow callers to override the request format, defaulting to JSON for
// consistent parsing. Set PHOTO_SELECT_OLLAMA_FORMAT to "" to omit the param.
const OLLAMA_FORMAT =
  process.env.PHOTO_SELECT_OLLAMA_FORMAT === ''
    ? null
    : process.env.PHOTO_SELECT_OLLAMA_FORMAT || 'json';

export default class OllamaProvider {
  async chat({ prompt, images, model, curators = [], maxRetries = 3, onProgress = () => {} }) {
    let attempt = 0;
    while (true) {
      try {
        onProgress('encoding');
        const { messages } = await buildMessages(prompt, images, curators);
        // Ollama's chat endpoint expects string content and a separate
        // `images` array. Flatten any multipart content and extract the
        // base64 images from the OpenAI-style structure produced by
        // `buildMessages`.
        const [system, user] = messages;
        const textParts = [];
        const imageData = [];
        if (Array.isArray(user.content)) {
          for (const part of user.content) {
            if (part.type === 'text') textParts.push(part.text);
            if (part.type === 'image_url' && part.image_url?.url) {
              const url = part.image_url.url;
              const match = url.match(/^data:image\/\w+;base64,(.*)$/);
              imageData.push(match ? match[1] : url);
            }
          }
        } else {
          textParts.push(String(user.content));
        }
        // Ollama vision models may ignore the "system" role. Embed the prompt
        // instructions into a single user message so every model sees them.
        const flatMessages = [
          {
            role: 'user',
            content: [
              system.content.trim(),
              '',
              textParts.join('\n'),
            ].join('\n'),
          },
        ];
        onProgress('request');
        const params = { model, messages: flatMessages, images: imageData, stream: false };

        // Ollama vision models fail if `format:"json"` is combined with images.
        // Only request JSON mode when no image data is present so text-only
        // conversations still benefit from structured output.
        if (OLLAMA_FORMAT && imageData.length === 0) {
          params.format = OLLAMA_FORMAT;
        }
        const res = await fetch(`${BASE_URL}/api/chat`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify(params),
        });
        if (res.status === 503) throw new Error('service unavailable');
        const data = await res.json().catch(() => ({}));
        if (!res.ok || data.error) {
          const msg = data.error || `HTTP ${res.status}`;
          throw new Error(msg);
        }
        if (!data.message?.content) {
          throw new Error('empty response');
        }
        onProgress('done');
        return data.message.content;
      } catch (err) {
        if (attempt >= maxRetries) throw err;
        attempt += 1;
        const wait = 2 ** attempt * 1000;
        console.warn(`ollama error (${err.message}). Retrying in ${wait}ms…`);
        await delay(wait);
      }
    }
  }
}
```

### File: ./src/providers/openai.js
```
import { chatCompletion } from '../chatClient.js';

export default class OpenAIProvider {
  async chat(opts) {
    return chatCompletion(opts);
  }
}
```

### File: ./src/index.js
```
#!/usr/bin/env node
/** Load environment variables ASAP (before any OpenAI import). */
import "dotenv/config";
import "./errorHandler.js";

import { Command } from "commander";
import path from "node:path";
import { DEFAULT_PROMPT_PATH } from "./templates.js";


const program = new Command();
program
  .name("photo-select")
  .description("Randomly triage photos with ChatGPT")
  .option("-d, --dir <path>", "Source directory of images", process.cwd())
  .option("-p, --prompt <file>", "Custom prompt file", DEFAULT_PROMPT_PATH)
  .option(
    "--provider <name>",
    "openai or ollama",
    process.env.PHOTO_SELECT_PROVIDER || "openai"
  )
  .option(
    "-m, --model <id>",
    "Model id (OpenAI or Ollama)",
    process.env.PHOTO_SELECT_MODEL
  )
  .option(
    "-k, --api-key <key>",
    "OpenAI API key",
    process.env.OPENAI_API_KEY
  )
  .option(
    "--ollama-base-url <url>",
    "Base URL for Ollama",
    process.env.OLLAMA_BASE_URL || "http://localhost:11434"
  )
  .option(
    "-c, --curators <names>",
    "Comma-separated list of curator names",
    (value) => value.split(',').map((n) => n.trim()).filter(Boolean),
    []
  )
  .option(
    "-x, --context <file>",
    "Text file with exhibition context for the curators"
  )
  .option("--no-recurse", "Process a single directory only")
  .option("-P, --parallel <n>", "Number of concurrent API calls", (v) => Math.max(1, parseInt(v, 10)), 1)
  .option("--field-notes", "Enable field notes workflow")
  .option("-v, --verbose", "Store prompts and responses for debugging")
  .parse(process.argv);

const {
  dir,
  prompt: promptPath,
  provider: providerName,
  model,
  recurse,
  apiKey,
  curators,
  context: contextPath,
  parallel,
  fieldNotes,
  verbose,
  ollamaBaseUrl,
} = program.opts();

if (apiKey) {
  process.env.OPENAI_API_KEY = apiKey;
}
if (ollamaBaseUrl) {
  process.env.OLLAMA_BASE_URL = ollamaBaseUrl;
}

const provider = providerName || 'openai';
let finalModel = model;
if (!finalModel) {
  finalModel = provider === 'ollama' ? 'qwen2.5vl:32b' : 'gpt-4o';
}

(async () => {
  try {
    if (provider === 'openai' && !process.env.OPENAI_API_KEY) {
      console.error(
        '❌  OPENAI_API_KEY is missing. Add it to a .env file or your shell env.'
      );
      process.exit(1);
    }
    const absDir = path.resolve(dir);
    const { triageDirectory } = await import('./orchestrator.js');
    const { getProvider } = await import('./providers/index.js');
    const driver = await getProvider(provider);
    await triageDirectory({
      dir: absDir,
      promptPath,
      provider: driver,
      model: finalModel,
      recurse,
      curators,
      contextPath,
      parallel,
      fieldNotes,
      verbose,
    });
    console.log("🎉  Finished triaging.");
  } catch (err) {
    console.error("❌  Error:", err);
    process.exit(1);
  }
})();
```

### File: ./src/config.js
```
/** Centralised config & helpers (Ember‑style “config owner”). */
export const SUPPORTED_EXTENSIONS = [
  ".jpg",
  ".jpeg",
  ".png",
  ".gif",
  ".tif",
  ".tiff",
  ".heic",
  ".heif",
];

// Prompt templates are compiled via renderTemplate in templates.js

/** Sleep helper for rate‑limit back‑off. */
export const delay = (ms) => new Promise((res) => setTimeout(res, ms));
```

### File: ./src/errorHandler.js
```
import { batchStore } from './batchContext.js';

process.on('uncaughtException', (err) => {
  if (err?.code === 'EPIPE') {
    const info = batchStore.getStore();
    const prefix = info?.batch ? `Batch ${info.batch} ` : '';
    console.warn(`\u26A0\uFE0F  ${prefix}socket error: ${err.message}`);
    return;
  }
  console.error('uncaught exception', err);
  process.exit(1);
});
```

### File: ./src/imageSelector.js
```
import fs from "node:fs/promises";
import path from "node:path";
import { SUPPORTED_EXTENSIONS } from "./config.js";

/** Return full paths of images in `dir` (non‑recursive). */
export async function listImages(dir) {
  const entries = await fs.readdir(dir, { withFileTypes: true });
  return entries
    .filter(
      (e) =>
        e.isFile() &&
        SUPPORTED_EXTENSIONS.includes(path.extname(e.name).toLowerCase())
    )
    .map((e) => path.join(dir, e.name))
    .sort();
}

/** Pick up to `count` random items from the array. */
export function pickRandom(array, count) {
  const shuffled = array.slice().sort(() => Math.random() - 0.5);
  return shuffled.slice(0, Math.min(count, array.length));
}

/** Ensure sub‑directories exist and move each file accordingly. */
export async function moveFiles(files, targetDir, notes = new Map()) {
  if (!files.length) return;
  await fs.mkdir(targetDir, { recursive: true });
  await Promise.all(
    files.map(async (file) => {
      const dest = path.join(targetDir, path.basename(file));
      await fs.rename(file, dest);
      const note = notes.get(file);
      if (note) {
        const txt = dest.replace(/\.[^.]+$/, ".txt");
        await fs.writeFile(txt, note, "utf8");
      }
    })
  );
}
```

### File: ./src/templates.js
```
import path from 'node:path';
import fs from 'node:fs/promises';
import Handlebars from 'handlebars';

export const DEFAULT_PROMPT_PATH = path.resolve(
  new URL('../prompts/default_prompt.hbs', import.meta.url).pathname
);

export async function renderTemplate(filePath = DEFAULT_PROMPT_PATH, data = {}) {
  const source = await fs.readFile(filePath, 'utf8');
  const template = Handlebars.compile(source, { noEscape: true });
  return template(data);
}

export async function buildPrompt(
  filePath,
  {
    curators = [],
    images = [],
    contextPath,
    fieldNotes,
    fieldNotesPrev,
    fieldNotesPrev2,
    commitMessages,
    hasFieldNotes = false,
    isSecondPass = false,
  }
) {
  const context = contextPath
    ? await fs.readFile(contextPath, 'utf8').catch(() => '')
    : '';
  return renderTemplate(filePath, {
    curators: curators.join(', '),
    images: images.map((f) => path.basename(f)),
    context,
    fieldNotes,
    fieldNotesPrev,
    fieldNotesPrev2,
    commitMessages,
    hasFieldNotes,
    isSecondPass,
  });
}

```

### File: ./src/fieldNotesWriter.js
```
import fs from 'node:fs/promises';
import fsSync from 'node:fs';
import path from 'node:path';
import os from 'node:os';
import crypto from 'node:crypto';
import { execFile } from 'node:child_process';
import { promisify } from 'node:util';
import { applyPatch } from 'diff';

const exec = promisify(execFile);

async function atomicWrite(file, text) {
  const dir = path.dirname(file);
  const tmp = path.join(dir, `.tmp-${crypto.randomUUID()}`);
  await fs.writeFile(tmp, text, 'utf8');
  await fs.rename(tmp, file);
}

function stripHeader(text) {
  return text.replace(/^##.*\n(?:created:.*\n)?(?:updated:.*\n)?\n?/, '');
}

function readHeader(text) {
  const match = text.match(/^created:\s*(.+)$/m);
  return match ? match[1].trim() : new Date().toISOString();
}

export default class FieldNotesWriter {
  constructor(file, level = '', execFn = exec) {
    this.file = file;
    this.level = level;
    this._exec = execFn;
  }

  async read() {
    try {
      const txt = await fs.readFile(this.file, 'utf8');
      return stripHeader(txt);
    } catch {
      return '';
    }
  }

  async init() {
    await fs.mkdir(path.dirname(this.file), { recursive: true });
    try {
      await fs.stat(this.file);
    } catch {
      const ts = new Date().toISOString();
      const header =
        (this.level ? `## Field Notes — Level ${this.level}\n` : '') +
        `created: ${ts}\n\n`;
      await atomicWrite(this.file, header);
    }
  }

  autolink(text) {
    const exts = '(?:jpg|jpeg|png|gif|tif|tiff|heic|heif)';
    const re = new RegExp(`(?<![\\[(])([\\w.-]+\\.${exts})`, 'gi');
    return text.replace(re, (m, name) => {
      const p = path.join(path.dirname(this.file), name);
      if (fsSync.existsSync(p)) return `[${name}](./${name})`;
      return m;
    });
  }

  async writeFull(markdown) {
    await this.init();
    const existing = await fs.readFile(this.file, 'utf8').catch(() => '');
    const created = readHeader(existing);
    const ts = new Date().toISOString();
    let body = this.autolink(markdown.trim());
    if ((body.match(/!\[/g) || []).length > 3) {
      body += '\n\n> **Warning**: Inline image limit exceeded.';
    }
    body += '\n';
    const header =
      (this.level ? `## Field Notes — Level ${this.level}\n` : '') +
      `created: ${created}\nupdated: ${ts}\n\n`;
    await atomicWrite(this.file, header + body);
  }

  async applyDiff(diffText) {
    await this.init();
    const old = await this.read();
    const dir = await fs.mkdtemp(path.join(os.tmpdir(), 'fn-'));
    const oldPath = path.join(dir, 'old.md');
    const patchPath = path.join(dir, 'patch.diff');
    await fs.writeFile(oldPath, old);
    await fs.writeFile(patchPath, diffText);
    let updated;
    try {
      await this._exec('patch', [oldPath, patchPath], { cwd: dir });
      updated = await fs.readFile(oldPath, 'utf8');
    } catch (err) {
      updated = applyPatch(old, diffText);
      if (updated === false) {
        await fs.rm(dir, { recursive: true, force: true });
        throw err;
      }
    }
    await fs.rm(dir, { recursive: true, force: true });
    await this.writeFull(updated);
  }
}

```

### File: ./src/orchestrator.js
```
import path from "node:path";
import { readFile, writeFile, mkdir, stat, copyFile } from "node:fs/promises";
import { execFile } from "node:child_process";
import { promisify } from "node:util";
import { batchStore } from "./batchContext.js";
import crypto from "node:crypto";
import { delay } from "./config.js";
import { listImages, pickRandom, moveFiles } from "./imageSelector.js";
import { parseReply } from "./chatClient.js";
import { buildPrompt } from "./templates.js";
import FieldNotesWriter from "./fieldNotesWriter.js";
import { MultiBar, Presets } from "cli-progress";

const exec = promisify(execFile);

async function ensureGitRepo(dir) {
  try {
    await stat(path.join(dir, ".git"));
  } catch {
    await exec("git", ["init"], { cwd: dir });
  }
}

async function commitFile(repoDir, file, message) {
  await exec("git", ["add", file], { cwd: repoDir });
  await exec("git", ["commit", "-m", message], { cwd: repoDir });
}

async function getRevisionHistory(repoDir, file, count = 2) {
  try {
    const rel = path.relative(repoDir, file);
    const { stdout } = await exec(
      "git",
      ["log", "--format=%H", "--follow", "--", rel],
      { cwd: repoDir }
    );
    const hashes = stdout.trim().split("\n").filter(Boolean);
    const versions = [];
    for (let i = 1; i <= count && i < hashes.length; i++) {
      const sha = hashes[i];
      const { stdout: content } = await exec(
        "git",
        ["show", `${sha}:${rel}`],
        { cwd: repoDir }
      );
      versions.push(content.trim());
    }
    return versions;
  } catch {
    return [];
  }
}

async function getCommitMessages(repoDir, file) {
  try {
    const rel = path.relative(repoDir, file);
    const { stdout } = await exec(
      "git",
      ["log", "--format=%s", "--follow", "--", rel],
      { cwd: repoDir }
    );
    return stdout.trim().split("\n").filter(Boolean);
  } catch {
    return [];
  }
}

function formatDuration(ms) {
  const sec = Math.round(ms / 1000);
  const h = Math.floor(sec / 3600);
  const m = Math.floor((sec % 3600) / 60);
  const s = sec % 60;
  if (h) return `${h}h ${m}m ${s}s`;
  if (m) return `${m}m ${s}s`;
  return `${s}s`;
}

/**
 * Recursively triage images until the current directory is empty
 * or contains only _keep/_aside folders.
 *
 * @param {Object} options
 * @param {string} options.dir    Directory of images to triage
 * @param {string} options.promptPath   Path to the base prompt
 * @param {Object} options.provider     Chat provider instance
 * @param {string} options.model        Model id for the provider
 * @param {boolean} [options.recurse=true]  Whether to descend into _keep folders
 * @param {string[]} [options.curators=[]]   Names inserted into the prompt
 * @param {string} [options.contextPath]     Optional additional context file
 * @param {number} [options.parallel=1]      Number of API requests to run simultaneously
 * @param {boolean} [options.fieldNotes=false] Enable field notes workflow
 * @param {number} [options.depth=0]         Internal recursion depth (for logging)
*/
export async function triageDirectory({
  dir,
  promptPath,
  provider,
  model,
  recurse = true,
  curators = [],
  contextPath,
  parallel = 1,
  fieldNotes = false,
  verbose = false,
  depth = 0,
  gitRoot,
}) {
  if (!provider) {
    const m = await import('./providers/openai.js');
    provider = new m.default();
  }
  const indent = "  ".repeat(depth);
  let notesWriter;

  if (!gitRoot) gitRoot = dir;
  if (fieldNotes && depth === 0) {
    await ensureGitRepo(gitRoot);
  }

  console.log(`${indent}📁  Scanning ${dir}`);

  // Archive original images at this level
  const levelDir = path.join(dir, `_level-${String(depth + 1).padStart(3, '0')}`);
  const initImages = await listImages(dir);
  const levelStart = Date.now();
  const totalImages = initImages.length;
  await mkdir(levelDir, { recursive: true });
  if (verbose) {
    await mkdir(path.join(levelDir, '_prompts'), { recursive: true });
    await mkdir(path.join(levelDir, '_responses'), { recursive: true });
  }
  const failedArchives = [];
  const copyFileSafe = async (
    src,
    dest,
    attempt = 0,
    maxAttempts = 3
  ) => {
    try {
      await copyFile(src, dest);
    } catch (err) {
      if (err?.code === "ECANCELED" && attempt < maxAttempts) {
        const wait = (attempt + 1) * 1000;
        console.warn(`${indent}⏳  Waiting for network file ${src} (${wait}ms)…`);
        try {
          await stat(src);
        } catch {
          // ignore
        }
        await delay(wait);
        return copyFileSafe(src, dest, attempt + 1, maxAttempts);
      }
      throw err;
    }
  };
  await Promise.all(
    initImages.map(async (file) => {
      const dest = path.join(levelDir, path.basename(file));
      try {
        await copyFileSafe(file, dest);
      } catch (err) {
        failedArchives.push(file);
        console.warn(`${indent}⚠️  Failed to archive ${file}: ${err.message}`);
      }
    })
  );
  if (failedArchives.length) {
    const listPath = path.join(levelDir, "failed-archives.txt");
    await writeFile(listPath, failedArchives.join("\n"), "utf8");
    console.warn(
      `${indent}⚠️  ${failedArchives.length} file(s) failed to archive; see ${listPath}`
    );
  }

  if (fieldNotes) {
    const lvl = String(depth + 1).padStart(3, '0');
    notesWriter = new FieldNotesWriter(path.join(levelDir, 'field-notes.md'), lvl);
    await notesWriter.init();
  }

  while (true) {
    const images = await listImages(dir);
    if (images.length === 0) {
      console.log(`${indent}✅  Nothing to do in ${dir}`);
      break;
    }

    console.log(`${indent}📊  ${images.length} unclassified image(s) found`);

    // Step 1 – select up to parallel × 10 images
    const total = Math.min(images.length, parallel * 10);
    const selection = pickRandom(images, total);
    console.log(`${indent}🔍  Selected ${selection.length} image(s)`);

    const batches = [];
    for (let i = 0; i < selection.length; i += 10) {
      batches.push(selection.slice(i, i + 10));
    }

    console.log(`${indent}⏳  Sending ${batches.length} batch(es) to ChatGPT…`);

    const multibar = new MultiBar(
      {
        clearOnComplete: false,
        hideCursor: true,
        format: `${indent}{prefix} |{bar}| {stage}`,
      },
      Presets.shades_classic
    );
    const stageMap = { encoding: 1, request: 2, waiting: 3, done: 4 };
    const bars = batches.map((_, i) =>
      multibar.create(4, 0, { prefix: `Batch ${i + 1}`, stage: "queued" })
    );

    let nextIndex = 0;
    async function worker() {
      while (true) {
        const idx = nextIndex++;
        if (idx >= batches.length) break;
        const batch = batches[idx];
        const bar = bars[idx];
        await batchStore.run({ batch: idx + 1 }, async () => {
          try {
            const notesText = notesWriter ? await notesWriter.read() : undefined;
            const basePrompt = await buildPrompt(promptPath, {
              curators,
              contextPath,
              images: batch,
              fieldNotes: notesText,
              hasFieldNotes: !!notesWriter,
              isSecondPass: false,
            });
            let prompt = basePrompt;
            const start = Date.now();
            const promptId = crypto.randomUUID();
            if (verbose) {
              const pFile = path.join(levelDir, '_prompts', `batch-${idx + 1}-${promptId}.txt`);
              await writeFile(pFile, prompt, 'utf8');
            }
            const reply = await provider.chat({
              prompt,
              images: batch,
              model,
              curators,
              onProgress: (stage) => {
                bar.update(stageMap[stage] || 0, { stage });
              },
              stream: true,
            });
            if (verbose) {
              const rFile = path.join(levelDir, '_responses', `batch-${idx + 1}-${promptId}.txt`);
              await writeFile(rFile, reply, 'utf8');
            }
            const ms = Date.now() - start;
            bar.update(4, { stage: "done" });
            bar.stop();
            console.log(`${indent}🤖  ChatGPT reply:\n${reply}`);
            console.log(`${indent}⏱️  Batch ${idx + 1} completed in ${(ms / 1000).toFixed(1)}s`);

            let parsed = parseReply(reply, batch, {
              expectFieldNotesInstructions: !!notesWriter,
            });
            const {
              keep,
              aside,
              notes,
              minutes,
              fieldNotesInstructions,
              fieldNotesMd,
            } = parsed;
            if (notesWriter && (fieldNotesMd || fieldNotesInstructions)) {
              if (fieldNotesMd) {
                await notesWriter.writeFull(fieldNotesMd);
                if (parsed.commitMessage) {
                  await commitFile(gitRoot, path.relative(gitRoot, notesWriter.file), parsed.commitMessage);
                }
              } else if (fieldNotesInstructions) {
                const [prev1 = "", prev2 = ""] = await getRevisionHistory(
                  gitRoot,
                  notesWriter.file,
                  2
                );
                const commitMsgs = await getCommitMessages(
                  gitRoot,
                  notesWriter.file
                );
                let secondPrompt = await buildPrompt(promptPath, {
                  curators,
                  contextPath,
                  images: batch,
                  fieldNotes: notesText,
                  fieldNotesPrev: prev1,
                  fieldNotesPrev2: prev2,
                  commitMessages: commitMsgs,
                  hasFieldNotes: !!notesWriter,
                  isSecondPass: true,
                });
                secondPrompt += `\nUpdate instructions:\n${fieldNotesInstructions}\n`;
                const secondId = crypto.randomUUID();
                if (verbose) {
                  const sp = path.join(levelDir, '_prompts', `batch-${idx + 1}-${secondId}-second.txt`);
                  await writeFile(sp, secondPrompt, 'utf8');
                }
                const second = await provider.chat({
                  prompt: secondPrompt,
                  images: batch,
                  model,
                  curators,
                  stream: true,
                  onProgress: (stage) => {
                    bar.update(stageMap[stage] || 0, { stage });
                  },
                });
                if (verbose) {
                  const sr = path.join(levelDir, '_responses', `batch-${idx + 1}-${secondId}-second.txt`);
                  await writeFile(sr, second, 'utf8');
                }
                parsed = parseReply(second, batch, { expectFieldNotesMd: true });
                if (parsed.fieldNotesMd) {
                  await notesWriter.writeFull(parsed.fieldNotesMd);
                  if (parsed.commitMessage) {
                    await commitFile(gitRoot, path.relative(gitRoot, notesWriter.file), parsed.commitMessage);
                  }
                }
              }
            }
            if (minutes.length) {
              const uuid = crypto.randomUUID();
              const minutesFile = path.join(dir, `minutes-${uuid}.txt`);
              await writeFile(minutesFile, minutes.join('\n'), 'utf8');
              console.log(`${indent}📝  Saved meeting minutes to ${minutesFile}`);
            }

            const keepDir = path.join(dir, "_keep");
            const asideDir = path.join(dir, "_aside");
            await Promise.all([
              moveFiles(keep, keepDir, notes),
              moveFiles(aside, asideDir, notes),
            ]);

            console.log(
              `📂  Moved: ${keep.length} keep → ${keepDir}, ${aside.length} aside → ${asideDir}`
            );
          } catch (err) {
            bar.update(4, { stage: "error" });
            bar.stop();
            console.warn(`${indent}⚠️  Batch ${idx + 1} failed: ${err.message}`);
          }
        });
      }
    }

    const workers = Array.from(
      { length: Math.min(parallel, batches.length) },
      () => worker()
    );
    await Promise.all(workers);
    multibar.stop();
    const remaining = (await listImages(dir)).length;
    const processed = totalImages - remaining;
    if (processed) {
      const elapsed = Date.now() - levelStart;
      const etaMs = (elapsed / processed) * remaining;
      console.log(`${indent}⏳  ETA to finish level: ${formatDuration(etaMs)}`);
    }
  }

  // Step 5 – recurse into keepDir if both keep and aside exist
  if (recurse) {
    const keepDir = path.join(dir, "_keep");
    const asideDir = path.join(dir, "_aside");
    let keepExists = false;
    try {
      keepExists = (await stat(keepDir)).isDirectory();
    } catch {
      // ignore
    }

    if (keepExists) {
      await triageDirectory({
        dir: keepDir,
        promptPath,
        provider,
        model,
        recurse,
        curators,
        contextPath,
        parallel,
        fieldNotes,
        depth: depth + 1,
        gitRoot,
      });
    } else {
      let keepCount = 0;
      let asideCount = 0;
      try {
        keepCount = (await listImages(keepDir)).length;
      } catch {
        // ignore
      }
      try {
        asideCount = (await listImages(asideDir)).length;
      } catch {
        // ignore
      }

      if (keepCount || asideCount) {
        const status = keepCount ? "kept" : "set aside";
        console.log(`${indent}🎯  All images ${status} at this level; stopping recursion.`);
      }
    }
  }
}
```


---

## 3. Basic System Report

Below is a snapshot of the system’s OS, architecture, date, uptime, disk usage, and memory usage.

### OS & Architecture
```
Darwin MacBook-Pro-2.local 24.4.0 Darwin Kernel Version 24.4.0: Fri Apr 11 18:33:39 PDT 2025; root:xnu-11417.101.15~117/RELEASE_ARM64_T6020 x86_64
```

### Detailed OS Version
```
ProductName:		macOS
ProductVersion:		15.4.1
BuildVersion:		24E263
```

### Current Date & Uptime
```
Tue Jul 29 14:46:57 EDT 2025
14:46  up 2 days,  2:37, 12 users, load averages: 2.94 5.47 5.71
```

### Disk Usage
```
Filesystem        Size    Used   Avail Capacity iused ifree %iused  Mounted on
/dev/disk3s1s1   7.3Ti    14Gi    65Gi    18%    425k  681M    0%   /
devfs            226Ki   226Ki     0Bi   100%     781     0  100%   /dev
/dev/disk3s6     7.3Ti   1.0Gi    65Gi     2%       1  681M    0%   /System/Volumes/VM
/dev/disk3s2     7.3Ti    13Gi    65Gi    17%    1.8k  681M    0%   /System/Volumes/Preboot
/dev/disk3s4     7.3Ti   685Mi    65Gi     2%     329  681M    0%   /System/Volumes/Update
/dev/disk1s2     500Mi   6.0Mi   481Mi     2%       1  4.9M    0%   /System/Volumes/xarts
/dev/disk1s1     500Mi   5.4Mi   481Mi     2%      36  4.9M    0%   /System/Volumes/iSCPreboot
/dev/disk1s3     500Mi   2.6Mi   481Mi     1%      65  4.9M    0%   /System/Volumes/Hardware
/dev/disk3s5     7.3Ti   7.2Ti    65Gi   100%    6.3M  681M    1%   /System/Volumes/Data
map auto_home      0Bi     0Bi     0Bi   100%       0     0     -   /System/Volumes/Data/home
/dev/disk6s1     8.0Gi   7.8Gi   239Mi    98%      13  2.4M    0%   /Library/Developer/CoreSimulator/Cryptex/Images/bundle/SimRuntimeBundle-5A827A60-A3C4-4EA5-A797-96042F68CA6C
/dev/disk8s1      18Gi    17Gi   461Mi    98%    444k  4.7M    9%   /Library/Developer/CoreSimulator/Volumes/iOS_22A3351
/dev/disk10s1    8.4Gi   8.1Gi   248Mi    98%      13  2.5M    0%   /Library/Developer/CoreSimulator/Cryptex/Images/bundle/SimRuntimeBundle-F5C6F012-5536-4988-8A2F-A3A204D4ABFE
/dev/disk12s1     18Gi    18Gi   472Mi    98%    459k  4.8M    9%   /Library/Developer/CoreSimulator/Volumes/iOS_22C150
/dev/disk2s1     5.0Gi   1.9Gi   3.1Gi    38%      64   33M    0%   /System/Volumes/Update/SFR/mnt1
/dev/disk4s1      30Gi    18Gi    12Gi    60%       0     0     -   /Volumes/DR-70D
/dev/disk3s1     7.3Ti    14Gi    65Gi    18%    426k  681M    0%   /System/Volumes/Update/mnt1
```

### Memory Usage
```
(Command 'free' not found on this system.)
```

### Installed RAM
```
Memory:

      Memory: 96 GB
      Type: LPDDR5
      Manufacturer: Hynix

```

## 4. Additional ML-Focused System Details

### GPU and CUDA Information
```
(nvidia-smi not found or no NVIDIA GPU installed.)

[system_profiler SPDisplaysDataType]
Graphics/Displays:

    Apple M2 Max:

      Chipset Model: Apple M2 Max
      Type: GPU
      Bus: Built-In
      Total Number of Cores: 38
      Vendor: Apple (0x106b)
      Metal Support: Metal 3
      Displays:
        Color LCD:
          Display Type: Built-in Liquid Retina XDR Display
          Resolution: 3024 x 1964 Retina
          Main Display: Yes
          Mirror: Off
          Online: Yes
          Automatically Adjust Brightness: Yes
          Connection Type: Internal
        S22C650:
          Resolution: 1920 x 1080 (1080p FHD - Full High Definition)
          UI Looks like: 1920 x 1080 @ 60.00Hz
          Mirror: Off
          Online: Yes

```

### Python Environment & Packages
```
[python3 -V]
Python 3.12.7

[pip3 freeze]
aiobotocore @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_1cl06d5vjc/croot/aiobotocore_1714464399334/work
aiohappyeyeballs @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_170hwh6b2i/croot/aiohappyeyeballs_1725434022310/work
aiohttp @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_4dbk4qcpk1/croot/aiohttp_1725527761629/work
aioitertools @ file:///tmp/build/80754af9/aioitertools_1607109665762/work
aiosignal @ file:///tmp/build/80754af9/aiosignal_1637843061372/work
alabaster @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_39uesgct45/croot/alabaster_1718201495024/work
altair @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/altair_1699282542592/work
anaconda-anon-usage @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_3eler6mjxh/croot/anaconda-anon-usage_1710965076906/work
anaconda-catalogs @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/anaconda-catalogs_1701813581302/work
anaconda-client @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_4fl23009pr/croot/anaconda-client_1708640644054/work
anaconda-cloud-auth @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_bazegf935a/croot/anaconda-cloud-auth_1713991395391/work
anaconda-navigator @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_dbsedxpmfb/croot/anaconda-navigator_1727709704056/work
anaconda-project @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_edkrilp7t2/croot/anaconda-project_1706049207276/work
annotated-types @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_1fa2djihwb/croot/annotated-types_1709542925772/work
anyio @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_a17a7759g2/croot/anyio_1706220182417/work
appdirs==1.4.4
applaunchservices @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_3ani429u_q/croot/applaunchservices_1710249784568/work
appnope @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/appnope_1699303798458/work
appscript @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_bev456p1le/croot/appscript_1725388760502/work
archspec @ file:///croot/archspec_1709217642129/work
argon2-cffi @ file:///opt/conda/conda-bld/argon2-cffi_1645000214183/work
argon2-cffi-bindings @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/argon2-cffi-bindings_1699251412744/work
arrow @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/arrow_1699251442701/work
astroid @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/astroid_1699240820293/work
astropy @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_fea_ls8y83/croot/astropy_1726174615584/work
astropy-iers-data @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_8elfwy87fe/croot/astropy-iers-data_1726000556608/work
asttokens @ file:///opt/conda/conda-bld/asttokens_1646925590279/work
async-lru @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/async-lru_1701803623704/work
atomicwrites==1.4.0
attrs @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/attrs_1699281960663/work
Automat @ file:///tmp/build/80754af9/automat_1600298431173/work
autopep8 @ file:///croot/autopep8_1708962882016/work
Babel @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/babel_1699241901875/work
bcrypt @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/bcrypt_1699241940700/work
beautifulsoup4 @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_94rx5n7wo9/croot/beautifulsoup4-split_1718029832430/work
binaryornot @ file:///tmp/build/80754af9/binaryornot_1617751525010/work
black @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_a1kx8enwxb/croot/black_1725573855432/work
bleach @ file:///opt/conda/conda-bld/bleach_1641577558959/work
blinker @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/blinker_1699238202041/work
bokeh @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_90dvw43ym1/croot/bokeh_1727914490404/work
boltons @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/boltons_1699240838368/work
botocore @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_733ekid_nr/croot/botocore_1714460542833/work
Bottleneck @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_e7wwl52wn1/croot/bottleneck_1709075893359/work
Brotli @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_27zk0eqdh0/croot/brotli-split_1714483157007/work
cachetools @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_6a4ekiifd5/croot/cachetools_1713977095290/work
certifi @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_0ecs_ou28u/croot/certifi_1725551740278/work/certifi
cffi @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_06ndtibm2c/croot/cffi_1726856446111/work
chardet @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/chardet_1699244713642/work
charset-normalizer @ file:///croot/charset-normalizer_1721748349566/work
click @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/click_1699237822453/work
cloudpickle @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_15c4lneh7c/croot/cloudpickle_1721657359029/work
colorama @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/colorama_1699282140182/work
colorcet @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_b4xbyn75js/croot/colorcet_1709758362167/work
comm @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_3doui0bmzb/croot/comm_1709322861485/work
conda @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_f0q92r98ek/croot/conda_1729193891987/work
conda-build @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_34v8f_chyc/croot/conda-build_1726839919610/work
conda-content-trust @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_9fusbfzixa/croot/conda-content-trust_1714483157715/work
conda-libmamba-solver @ file:///croot/conda-libmamba-solver_1727775630457/work/src
conda-pack @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_bf7z50aw6o/croot/conda-pack_1710258031692/work
conda-package-handling @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_ef9phnqphe/croot/conda-package-handling_1718138279942/work
conda-repo-cli @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_f19ffcbhgt/croot/conda-repo-cli_1727366914573/work
conda-token @ file:///croot/conda-token_1718995751285/work
conda_index @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_0au56q2_5k/croot/conda-index_1719338215248/work
conda_package_streaming @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_6dgq200203/croot/conda-package-streaming_1718136087190/work
constantly @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_efw7euxpjs/croot/constantly_1703165606144/work
contourpy @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/contourpy_1701814001737/work
cookiecutter @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_38jzqhs2jm/croot/cookiecutter_1711059824217/work
cryptography @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_51oymkxnaj/croot/cryptography_1724940565328/work
cssselect @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_47oh46v5h0/croot/cssselect_1707339886455/work
cycler @ file:///tmp/build/80754af9/cycler_1637851556182/work
cytoolz @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_f0etqooaak/croot/cytoolz_1701723613874/work
dask @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_aaiijmokbm/croot/dask-core_1725461363220/work
dask-expr @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_e54n8hzk7f/croot/dask-expr_1725523003908/work
datashader @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_fbalsd7ww9/croot/datashader_1720540173106/work
debugpy @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/debugpy_1699253073094/work
decorator @ file:///opt/conda/conda-bld/decorator_1643638310831/work
defusedxml @ file:///tmp/build/80754af9/defusedxml_1615228127516/work
diff-match-patch @ file:///Users/ktietz/demo/mc3/conda-bld/diff-match-patch_1630511840874/work
dill @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_28zwy_olqk/croot/dill_1715094676263/work
distributed @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_fflqhqrq0u/croot/distributed_1725523026486/work
distro @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_ddkyz0575y/croot/distro_1714488254309/work
dmglib @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_e8vusks82c/croot/dmglib_1719996269222/work
docstring-to-markdown @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/docstring-to-markdown_1699242114044/work
docutils @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/docutils_1699238275731/work
et-xmlfile @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/et_xmlfile_1699245044998/work
executing @ file:///opt/conda/conda-bld/executing_1646925071911/work
fastjsonschema @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/python-fastjsonschema_1699238535414/work
filelock @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/filelock_1701804468261/work
flake8 @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_8fyuzhayos/croot/flake8_1708965272166/work
Flask @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_b6zka5i2cn/croot/flask_1716545886197/work
fonttools @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_60c8ux4mkl/croot/fonttools_1713551354374/work
frozendict @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_8b0cest_id/croot/frozendict_1713194839836/work
frozenlist @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/frozenlist_1699254257028/work
fsspec @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_436le7786l/croot/fsspec_1724855598709/work
gensim @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_5cdoei19at/croot/gensim_1725057952958/work
gitdb @ file:///tmp/build/80754af9/gitdb_1617117951232/work
GitPython @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_ebpnpowk3c/croot/gitpython_1720455037823/work
greenlet @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_516imz09pb/croot/greenlet_1702059966336/work
h11 @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_110bmw2coo/croot/h11_1706652289620/work
h5py @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_4ed_3jzwco/croot/h5py_1715094733352/work
HeapDict @ file:///Users/ktietz/demo/mc3/conda-bld/heapdict_1630598515714/work
holoviews @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_d9699cvcyt/croot/holoviews_1720539755521/work
httpcore @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_fcxiho9nv7/croot/httpcore_1706728465004/work
httpx @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_cc4egw1482/croot/httpx_1723474826664/work
hvplot @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_c6l1nubo_c/croot/hvplot_1727775577392/work
hyperlink @ file:///tmp/build/80754af9/hyperlink_1610130746837/work
idna @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_a12xpo84t2/croot/idna_1714398852854/work
imagecodecs @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/imagecodecs_1699241106295/work
imageio @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_3d_rw6fwwk/croot/imageio_1707247298334/work
imagesize @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/imagesize_1699242222508/work
imbalanced-learn @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_2fmriz1nk5/croot/imbalanced-learn_1718132237893/work
importlib-metadata @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_5498c88e7n/croot/importlib_metadata-suite_1704813534254/work
incremental @ file:///croot/incremental_1708639938299/work
inflection @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/inflection_1699245330843/work
iniconfig @ file:///home/linux1/recipes/ci/iniconfig_1610983019677/work
intake @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_9coumc4ufj/croot/intake_1726109564581/work
intervaltree @ file:///Users/ktietz/demo/mc3/conda-bld/intervaltree_1630511889664/work
ipykernel @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_f428_5tjvx/croot/ipykernel_1705933835534/work
ipython @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_31k34m3e25/croot/ipython_1726064238879/work
ipython-genutils @ file:///tmp/build/80754af9/ipython_genutils_1606773439826/work
ipywidgets @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_01t3jhj_j9/croot/ipywidgets_1710961498393/work
isort @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_1bnvhw7_ex/croot/isort_1718291367347/work
itemadapter @ file:///tmp/build/80754af9/itemadapter_1626442940632/work
itemloaders @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_9810zcegev/croot/itemloaders_1708639928835/work
itsdangerous @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_00jdi1gu23/croot/itsdangerous_1716533346702/work
jaraco.classes @ file:///tmp/build/80754af9/jaraco.classes_1620983179379/work
jedi @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_194648shy3/croot/jedi_1721058355221/work
jellyfish @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/jellyfish_1699255065421/work
Jinja2 @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_44yzu12j7f/croot/jinja2_1716993410427/work
jmespath @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/jmespath_1701804490553/work
joblib @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_8ff7uji0v2/croot/joblib_1718217225309/work
json5 @ file:///tmp/build/80754af9/json5_1624432770122/work
jsonpatch @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_3ajyoz8zoj/croot/jsonpatch_1714483362270/work
jsonpointer==2.1
jsonschema @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_7boelfqucq/croot/jsonschema_1728486715888/work
jsonschema-specifications @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/jsonschema-specifications_1701803122948/work
jupyter @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_c2jou6olpk/croot/jupyter_1709837195270/work
jupyter-console @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/jupyter_console_1707340206137/work
jupyter-events @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_db0avcjzq5/croot/jupyter_events_1718738111427/work
jupyter-lsp @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/jupyter-lsp-meta_1707339967035/work
jupyter_client @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/jupyter_client_1701803191601/work
jupyter_core @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_73nomeum4p/croot/jupyter_core_1718818302815/work
jupyter_server @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_d1t69bk94b/croot/jupyter_server_1718827086930/work
jupyter_server_terminals @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/jupyter_server_terminals_1701803399551/work
jupyterlab @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_a2d0br6r6g/croot/jupyterlab_1725895226942/work
jupyterlab-pygments @ file:///tmp/build/80754af9/jupyterlab_pygments_1601490720602/work
jupyterlab-widgets @ file:///tmp/build/80754af9/jupyterlab_widgets_1609884341231/work
jupyterlab_server @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_f64fg3hglz/croot/jupyterlab_server_1725865356410/work
keyring @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_8fybah8hcr/croot/keyring_1709632516643/work
kiwisolver @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/kiwisolver_1699239145780/work
lazy-object-proxy @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_56nrnaax6j/croot/lazy-object-proxy_1712908715628/work
lazy_loader @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_e4fhv6eyhq/croot/lazy_loader_1718176742928/work
lckr_jupyterlab_variableinspector @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/jupyterlab-variableinspector_1709224907973/work
libarchive-c @ file:///croot/python-libarchive-c_1726069797193/work
libmambapy @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_14wu5sk1ap/croot/mamba-split_1725563369022/work/libmambapy
linkify-it-py @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/linkify-it-py_1699255587400/work
llvmlite @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_22a8mvi_vz/croot/llvmlite_1720455324093/work
lmdb @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/python-lmdb_1699242995414/work
locket @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/locket_1699239197253/work
lxml @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_e656pjhd5l/croot/lxml_1722882197113/work
lz4 @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/lz4_1699258569924/work
Markdown @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/markdown_1699247849754/work
markdown-it-py @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/markdown-it-py_1699237863445/work
MarkupSafe @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/markupsafe_1707339878470/work
matplotlib==3.9.2
matplotlib-inline @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/matplotlib-inline_1699242375920/work
mccabe @ file:///opt/conda/conda-bld/mccabe_1644221741721/work
mdit-py-plugins @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/mdit-py-plugins_1699258689091/work
mdurl @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/mdurl_1699237660008/work
menuinst @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_ad321a45td/croot/menuinst_1723567614652/work
mistune @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/mistune_1699258805653/work
more-itertools @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_1di4owdn65/croot/more-itertools_1727185454223/work
mpmath @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/mpmath_1699242500508/work
msgpack @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/msgpack-python_1699237897243/work
multidict @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_10voz9m15i/croot/multidict_1701096890858/work
multipledispatch @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/multipledispatch_1699237920047/work
mypy @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_fdoskmy3x7/croot/mypy-split_1725573898279/work
mypy-extensions @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/mypy_extensions_1699241356727/work
navigator-updater @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_15xz58jgev/croot/navigator-updater_1718030392983/work
nbclient @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/nbclient_1701803280377/work
nbconvert @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_f4c1s1qk1f/croot/nbconvert_1728049432295/work
nbformat @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_2cv_qoc1gw/croot/nbformat_1728049423516/work
nest-asyncio @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_310vb5e2a0/croot/nest-asyncio_1708532678212/work
networkx @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_70xddlxyrl/croot/networkx_1720002492248/work
nltk @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_66jwomcxtp/croot/nltk_1724427705781/work
notebook @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_539v4hufo2/croot/notebook_1727199149603/work
notebook_shim @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/notebook-shim_1707340024494/work
numba @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_adaws2bya8/croot/numba_1720607446395/work
numexpr @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/numexpr_1699237935415/work
numpy @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_a51i_mbs7m/croot/numpy_and_numpy_base_1708638620867/work/dist/numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl#sha256=37afb6b734a197702d848df93bd67c10b52f6467d56e518950d84b6b1c949d27
numpydoc @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_69xghc3i3n/croot/numpydoc_1718279166747/work
openpyxl @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_96hhik4ygv/croot/openpyxl_1721752931204/work
overrides @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/overrides_1701803470591/work
packaging @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_81ri4yfpjw/croot/packaging_1720101866878/work
pandas @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_b53hgou29t/croot/pandas_1718308972393/work/dist/pandas-2.2.2-cp312-cp312-macosx_11_0_arm64.whl#sha256=1956b71d1baac8b370fd9deac6100aadefda112447dca816a81ecbf3ea4eb3e6
pandocfilters @ file:///opt/conda/conda-bld/pandocfilters_1643405455980/work
panel @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_68psfg10tp/croot/panel_1728066379997/work
param @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_b966xs8glj/croot/param_1719347934708/work
parsel @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_da55frlnfu/croot/parsel_1707503460023/work
parso @ file:///opt/conda/conda-bld/parso_1641458642106/work
partd @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/partd_1699241371660/work
pathspec @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/pathspec_1699237228964/work
patsy @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_70o6mid86v/croot/patsy_1718378180175/work
pexpect @ file:///tmp/build/80754af9/pexpect_1605563209008/work
pickleshare @ file:///tmp/build/80754af9/pickleshare_1606932040724/work
pillow @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_617xe_y58w/croot/pillow_1721059447446/work
pkce @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/pkce_1699241403777/work
pkginfo @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_21aly_cba3/croot/pkginfo_1715695988648/work
platformdirs @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/platformdirs_1701803010714/work
plotly @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_c4cwziyfrp/croot/plotly_1726245572537/work
pluggy @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/pluggy_1699237243543/work
ply @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/ply_1699237976675/work
prometheus-client @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/prometheus_client_1699242791845/work
prompt-toolkit @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_c63v4kqjzr/croot/prompt-toolkit_1704404354115/work
Protego @ file:///tmp/build/80754af9/protego_1598657180827/work
protobuf==4.25.3
psutil @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/psutil_1699248249804/work
ptyprocess @ file:///tmp/build/80754af9/ptyprocess_1609355006118/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl
pure-eval @ file:///opt/conda/conda-bld/pure_eval_1646925070566/work
py-cpuinfo @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/py-cpuinfo_1699242825254/work
pyarrow @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_36v5ad2oyu/croot/pyarrow_1721673857195/work/python
pyasn1 @ file:///Users/ktietz/demo/mc3/conda-bld/pyasn1_1629708007385/work
pyasn1-modules==0.2.8
pycodestyle @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_eeqv1b4oo7/croot/pycodestyle_1701910176728/work
pycosat @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_19qelmdbl6/croot/pycosat_1714510743067/work
pycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work
pyct @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/pyct_1699248363282/work
pycurl @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_da76jm_izu/croot/pycurl_1725370249316/work
pydantic @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_6a3ae3hfnm/croot/pydantic_1725040525203/work
pydantic_core @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_636oiyd6i5/croot/pydantic-core_1724790368915/work
pydeck @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_df_5iy65um/croot/pydeck_1706194077123/work
PyDispatcher @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/pydispatcher_1699248379667/work
pydocstyle @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/pydocstyle_1699242840130/work
pyerfa @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_4b_blcl5tb/croot/pyerfa_1717700766739/work
pyflakes @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_bbjb40dmuh/croot/pyflakes_1708962969108/work
Pygments @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/pygments_1699238063295/work
PyJWT @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_e55dbbf3h7/croot/pyjwt_1715094746385/work
pylint @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/pylint_1699242870766/work
pylint-venv @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_80rsj1kckp/croot/pylint-venv_1709837627074/work
pyls-spyder==0.4.0
pyobjc-core @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_342uq4g0a3/croot/pyobjc-core_1710189033492/work
pyobjc-framework-Cocoa @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_157_nv38zo/croot/pyobjc-framework-cocoa_1710191895205/work
pyobjc-framework-CoreServices @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_88_zqrgmok/croot/pyobjc-framework-coreservices_1710193940178/work
pyobjc-framework-FSEvents @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_c2fjwa8ak_/croot/pyobjc-framework-fsevents_1710193216694/work
pyodbc @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_6fm48uguvm/croot/pyodbc_1725560248566/work
pyOpenSSL @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_55z9ffoadh/croot/pyopenssl_1723651585773/work
pyparsing @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_8a270krrj3/croot/pyparsing_1725041637835/work
PyQt5==5.15.10
PyQt5-sip @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/pyqt-split_1699239482609/work/pyqt_sip
PyQtWebEngine==5.15.6
PySocks @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/pysocks_1699237568675/work
pytest @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_3ailxghqbl/croot/pytest_1717793250782/work
python-dateutil @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_66ud1l42_h/croot/python-dateutil_1716495741162/work
python-dotenv @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/python-dotenv_1699238520458/work
python-json-logger @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/python-json-logger_1699249563021/work
python-lsp-black @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_82mkiw3l7w/croot/python-lsp-black_1709232912184/work
python-lsp-jsonrpc @ file:///croot/python-lsp-jsonrpc_1708962872556/work
python-lsp-server @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_bdnoklk478/croot/python-lsp-server_1708971744028/work
python-slugify @ file:///tmp/build/80754af9/python-slugify_1620405669636/work
pytoolconfig @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_c0c43xm9fv/croot/pytoolconfig_1701728714940/work
pytz @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_a4b76c83ik/croot/pytz_1713974318928/work
pyviz_comms @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_c98m0kf4qk/croot/pyviz_comms_1711136840525/work
PyWavelets @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_daz4vp9nbh/croot/pywavelets_1725657952023/work
PyYAML @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/pyyaml_1699240344586/work
pyzmq @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_43pxpbos3z/croot/pyzmq_1705605108344/work
QDarkStyle @ file:///croot/qdarkstyle_1709231003551/work
qstylizer @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/qstylizer_1699262427573/work/dist/qstylizer-0.2.2-py2.py3-none-any.whl#sha256=cd3b31aa7090b6c66ce5853330138531f3c0dde133f5a7f1e8a395c62fa57ac1
QtAwesome @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_50dnstqs1c/croot/qtawesome_1726169352530/work
qtconsole @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_cfdakfnvf3/croot/qtconsole_1709231159186/work
QtPy @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/qtpy_1701804233944/work
queuelib @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/queuelib_1699249732700/work
referencing @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/referencing_1701803099840/work
regex @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_2cy04sgiwf/croot/regex_1726650046753/work
requests @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_70sm12ba9w/croot/requests_1721414707360/work
requests-file @ file:///Users/ktietz/demo/mc3/conda-bld/requests-file_1629455781986/work
requests-toolbelt @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/requests-toolbelt_1699238632371/work
rfc3339-validator @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/rfc3339-validator_1699249772675/work
rfc3986-validator @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/rfc3986-validator_1699249792387/work
rich @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_bcb8hqb_r4/croot/rich_1720637498249/work
rope @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_337no7p3xs/croot/rope_1708963178733/work
rpds-py @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/rpds-py_1699262599461/work
Rtree @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/rtree_1699262640425/work
ruamel-yaml-conda @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/ruamel_yaml_1699249814223/work
ruamel.yaml @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35yvtl3p84/croot/ruamel.yaml_1727980165481/work
ruamel.yaml.clib @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_70l_orv46q/croot/ruamel.yaml.clib_1727769819918/work
s3fs @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_fa25uuxfjq/croot/s3fs_1724924107705/work
scikit-image @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d6j00jzmsp/croot/scikit-image_1726737419383/work
scikit-learn @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_97o1ht3oty/croot/scikit-learn_1721921878202/work
scipy @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_b9t0odioph/croot/scipy_1717521487325/work/dist/scipy-1.13.1-cp312-cp312-macosx_11_0_arm64.whl#sha256=79bc68b8b51505a63d293435b261c75d43ce266b063378b789d9805b3a33fcc0
Scrapy @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_26idk0ntp9/croot/scrapy_1708714690612/work
seaborn @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_f3_ueh70ud/croot/seaborn_1718302932585/work
semver @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_99ujwp04tw/croot/semver_1709243633470/work
Send2Trash @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/send2trash_1701803532643/work
service-identity @ file:///Users/ktietz/demo/mc3/conda-bld/service_identity_1629460757137/work
setuptools==75.1.0
sip @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/sip_1699238710791/work
six @ file:///tmp/build/80754af9/six_1644875935023/work
smart-open @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/smart_open_1699241638232/work
smmap @ file:///tmp/build/80754af9/smmap_1611694433573/work
sniffio @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_1573pknjrg/croot/sniffio_1705431298885/work
snowballstemmer @ file:///tmp/build/80754af9/snowballstemmer_1637937080595/work
sortedcontainers @ file:///tmp/build/80754af9/sortedcontainers_1623949099177/work
soupsieve @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/soupsieve_1699282494776/work
Sphinx @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_50hy2c49dh/croot/sphinx_1718275395179/work
sphinxcontrib-applehelp @ file:///home/ktietz/src/ci/sphinxcontrib-applehelp_1611920841464/work
sphinxcontrib-devhelp @ file:///home/ktietz/src/ci/sphinxcontrib-devhelp_1611920923094/work
sphinxcontrib-htmlhelp @ file:///tmp/build/80754af9/sphinxcontrib-htmlhelp_1623945626792/work
sphinxcontrib-jsmath @ file:///home/ktietz/src/ci/sphinxcontrib-jsmath_1611920942228/work
sphinxcontrib-qthelp @ file:///home/ktietz/src/ci/sphinxcontrib-qthelp_1611921055322/work
sphinxcontrib-serializinghtml @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_c0gy7ylkec/croot/sphinxcontrib-serializinghtml_1718201677157/work
spyder @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_892g68m5sn/croot/spyder_1727198303638/work
spyder-kernels @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_42vj8220mm/croot/spyder-kernels_1707937716590/work
SQLAlchemy @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_3frqduvs8h/croot/sqlalchemy_1725885054432/work
stack-data @ file:///opt/conda/conda-bld/stack_data_1646927590127/work
statsmodels @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_af8vmuwbis/croot/statsmodels_1718381196260/work
streamlit @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_52t8o6xfs8/croot/streamlit_1724335169234/work
sympy @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_12ufyeicwp/croot/sympy_1724938200081/work
tables @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_b6xsinywwn/croot/pytables_1725380789988/work
tabulate @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/tabulate_1701807377411/work
tblib @ file:///Users/ktietz/demo/mc3/conda-bld/tblib_1629402031467/work
tenacity @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_e4laqy9gpr/croot/tenacity_1721222508993/work
terminado @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/terminado_1699283001768/work
text-unidecode @ file:///Users/ktietz/demo/mc3/conda-bld/text-unidecode_1629401354553/work
textdistance @ file:///tmp/build/80754af9/textdistance_1612461398012/work
threadpoolctl @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_efa5bvb6vi/croot/threadpoolctl_1719407806403/work
three-merge @ file:///tmp/build/80754af9/three-merge_1607553261110/work
tifffile @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/tifffile_1699243525693/work
tinycss2 @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/tinycss2_1699250325251/work
tldextract @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_86f1bw02kg/croot/tldextract_1723064389239/work
toml @ file:///tmp/build/80754af9/toml_1616166611790/work
tomli @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/tomli_1699237289925/work
tomlkit @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/tomlkit_1699238737474/work
toolz @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/toolz_1699238160466/work
tornado @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_a4w03z48br/croot/tornado_1718740114858/work
tqdm @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_24zjwympsr/croot/tqdm_1724853942429/work
traitlets @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_500m2_1wyk/croot/traitlets_1718227071952/work
truststore @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/truststore_1701805928787/work
Twisted @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_c4spem5kwe/croot/twisted_1708702820544/work
typing_extensions @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_93dg13ilv4/croot/typing_extensions_1715268840722/work
tzdata @ file:///croot/python-tzdata_1690578112552/work
uc-micro-py @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/uc-micro-py_1699250544885/work
ujson @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_dexxju769y/croot/ujson_1717597527341/work
unicodedata2 @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_a3epjto7gs/croot/unicodedata2_1713212955584/work
Unidecode @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_33gnubyv29/croot/unidecode_1724790055767/work
urllib3 @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_06_m8gdsy6/croot/urllib3_1727769822458/work
w3lib @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/w3lib_1709223508304/work
watchdog @ file:///Users/builder/cbouss/crwatchdog/watchdog_1717177010913/work
wcwidth @ file:///Users/ktietz/demo/mc3/conda-bld/wcwidth_1629357192024/work
webencodings @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/webencodings_1699243630039/work
websocket-client @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_d37u7gqts8/croot/websocket-client_1715878310260/work
Werkzeug @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_5bnbxlhunm/croot/werkzeug_1716533322814/work
whatthepatch @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/whatthepatch_1699243659982/work
wheel==0.44.0
widgetsnbextension @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_45ynevdsp5/croot/widgetsnbextension_1710960054121/work
wrapt @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/wrapt_1699240702378/work
wurlitzer @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/wurlitzer_1699265832005/work
xarray @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/xarray_1699240726099/work
xlwings @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_1cs4qhgbiw/croot/xlwings_1725400081092/work
xyzservices @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/xyzservices_1699243674756/work
yapf @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_29ra4n2npe/croot/yapf_1708964324475/work
yarl @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_9et2w8mlgu/croot/yarl_1725976501637/work
zict @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/zict_1699250947936/work
zipp @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/zipp_1707348942775/work
zope.interface @ file:///Users/builder/cbouss/perseverance-python-buildout/croot/zope.interface_1699243689919/work
zstandard @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_cairdg5u3o/croot/zstandard_1728569200438/work

[conda info --envs]
# conda environments:
#
                         /Users/jburkart/mamba/envs/deepseek-mps
base                  *  /opt/anaconda3
zoom-browser             /opt/anaconda3/envs/zoom-browser


[conda list --show-channel-urls]
# packages in environment at /opt/anaconda3:
#
# Name                    Version                   Build  Channel
_anaconda_depends         2024.10         py312_openblas_0    defaults
aiobotocore               2.12.3          py312hca03da5_0    defaults
aiohappyeyeballs          2.4.0           py312hca03da5_0    defaults
aiohttp                   3.10.5          py312h80987f9_0    defaults
aioitertools              0.7.1              pyhd3eb1b0_0    defaults
aiosignal                 1.2.0              pyhd3eb1b0_0    defaults
alabaster                 0.7.16          py312hca03da5_0    defaults
altair                    5.0.1           py312hca03da5_0    defaults
anaconda-anon-usage       0.4.4           py312hd6b623d_100    defaults
anaconda-catalogs         0.2.0           py312hca03da5_1    defaults
anaconda-client           1.12.3          py312hca03da5_0    defaults
anaconda-cloud-auth       0.5.1           py312hca03da5_0    defaults
anaconda-navigator        2.6.3           py312hca03da5_0    defaults
anaconda-project          0.11.1          py312hca03da5_0    defaults
annotated-types           0.6.0           py312hca03da5_0    defaults
anyio                     4.2.0           py312hca03da5_0    defaults
aom                       3.6.0                h313beb8_0    defaults
appdirs                   1.4.4              pyhd3eb1b0_0    defaults
applaunchservices         0.3.0           py312hca03da5_0    defaults
appnope                   0.1.3           py312hca03da5_1001    defaults
appscript                 1.2.5           py312h80987f9_0    defaults
archspec                  0.2.3              pyhd3eb1b0_0    defaults
argon2-cffi               21.3.0             pyhd3eb1b0_0    defaults
argon2-cffi-bindings      21.2.0          py312h80987f9_0    defaults
arrow                     1.2.3           py312hca03da5_1    defaults
arrow-cpp                 16.1.0               hbc20fb2_0    defaults
astroid                   2.14.2          py312hca03da5_0    defaults
astropy                   6.1.3           py312h80987f9_0    defaults
astropy-iers-data         0.2024.9.2.0.33.23 py312hca03da5_0    defaults
asttokens                 2.0.5              pyhd3eb1b0_0    defaults
async-lru                 2.0.4           py312hca03da5_0    defaults
atomicwrites              1.4.0                      py_0    defaults
attrs                     23.1.0          py312hca03da5_0    defaults
automat                   20.2.0                     py_0    defaults
autopep8                  2.0.4              pyhd3eb1b0_0    defaults
aws-c-auth                0.6.19               h80987f9_0    defaults
aws-c-cal                 0.5.20               h80987f9_0    defaults
aws-c-common              0.8.5                h80987f9_0    defaults
aws-c-compression         0.2.16               h80987f9_0    defaults
aws-c-event-stream        0.2.15               h313beb8_0    defaults
aws-c-http                0.6.25               h80987f9_0    defaults
aws-c-io                  0.13.10              h80987f9_0    defaults
aws-c-mqtt                0.7.13               h80987f9_0    defaults
aws-c-s3                  0.1.51               h80987f9_0    defaults
aws-c-sdkutils            0.1.6                h80987f9_0    defaults
aws-checksums             0.1.13               h80987f9_0    defaults
aws-crt-cpp               0.18.16              h313beb8_0    defaults
aws-sdk-cpp               1.10.55              h313beb8_0    defaults
babel                     2.11.0          py312hca03da5_0    defaults
bcrypt                    3.2.0           py312h80987f9_1    defaults
beautifulsoup4            4.12.3          py312hca03da5_0    defaults
binaryornot               0.4.4              pyhd3eb1b0_1    defaults
black                     24.8.0          py312hca03da5_0    defaults
blas                      1.0                    openblas    defaults
bleach                    4.1.0              pyhd3eb1b0_0    defaults
blinker                   1.6.2           py312hca03da5_0    defaults
blosc                     1.21.3               h313beb8_0    defaults
bokeh                     3.6.0           py312hca03da5_0    defaults
boltons                   23.0.0          py312hca03da5_0    defaults
boost-cpp                 1.82.0               h48ca7d4_2    defaults
botocore                  1.34.69         py312hca03da5_0    defaults
bottleneck                1.3.7           py312ha86b861_0    defaults
brotli                    1.0.9                h80987f9_8    defaults
brotli-bin                1.0.9                h80987f9_8    defaults
brotli-python             1.0.9           py312h313beb8_8    defaults
brunsli                   0.1                  hc377ac9_1    defaults
bzip2                     1.0.8                h80987f9_6    defaults
c-ares                    1.19.1               h80987f9_0    defaults
c-blosc2                  2.12.0               h7df6c2f_0    defaults
ca-certificates           2024.9.24            hca03da5_0    defaults
cachetools                5.3.3           py312hca03da5_0    defaults
cctools                   949.0.1             hc179dcd_25    defaults
cctools_osx-arm64         949.0.1             h332cad3_25    defaults
certifi                   2024.8.30       py312hca03da5_0    defaults
cffi                      1.17.1          py312h3eb5a62_0    defaults
cfitsio                   3.470                h7f6438f_7    defaults
chardet                   4.0.0           py312hca03da5_1003    defaults
charls                    2.2.0                hc377ac9_0    defaults
charset-normalizer        3.3.2              pyhd3eb1b0_0    defaults
click                     8.1.7           py312hca03da5_0    defaults
cloudpickle               3.0.0           py312hca03da5_0    defaults
colorama                  0.4.6           py312hca03da5_0    defaults
colorcet                  3.1.0           py312hca03da5_0    defaults
comm                      0.2.1           py312hca03da5_0    defaults
conda                     24.9.2          py312hca03da5_0    defaults
conda-build               24.9.0          py312hca03da5_0    defaults
conda-content-trust       0.2.0           py312hca03da5_1    defaults
conda-index               0.5.0           py312hca03da5_0    defaults
conda-libmamba-solver     24.9.0             pyhd3eb1b0_0    defaults
conda-pack                0.7.1           py312hca03da5_0    defaults
conda-package-handling    2.3.0           py312hca03da5_0    defaults
conda-package-streaming   0.10.0          py312hca03da5_0    defaults
conda-repo-cli            1.0.114         py312hca03da5_0    defaults
conda-token               0.5.0              pyhd3eb1b0_0    defaults
constantly                23.10.4         py312hca03da5_0    defaults
contourpy                 1.2.0           py312h48ca7d4_0    defaults
cookiecutter              2.6.0           py312hca03da5_0    defaults
cryptography              43.0.0          py312hd4332d6_0    defaults
cssselect                 1.2.0           py312hca03da5_0    defaults
curl                      8.9.1                h02f6b3c_0    defaults
cycler                    0.11.0             pyhd3eb1b0_0    defaults
cyrus-sasl                2.1.28               h9131b1a_1    defaults
cytoolz                   0.12.2          py312h80987f9_0    defaults
dask                      2024.8.2        py312hca03da5_0    defaults
dask-core                 2024.8.2        py312hca03da5_0    defaults
dask-expr                 1.1.13          py312hca03da5_0    defaults
datashader                0.16.3          py312hca03da5_0    defaults
dav1d                     1.2.1                h80987f9_0    defaults
debugpy                   1.6.7           py312h313beb8_0    defaults
decorator                 5.1.1              pyhd3eb1b0_0    defaults
defusedxml                0.7.1              pyhd3eb1b0_0    defaults
diff-match-patch          20200713           pyhd3eb1b0_0    defaults
dill                      0.3.8           py312hca03da5_0    defaults
distributed               2024.8.2        py312hca03da5_0    defaults
distro                    1.9.0           py312hca03da5_0    defaults
dmglib                    0.9.5           py312hca03da5_0    defaults
docstring-to-markdown     0.11            py312hca03da5_0    defaults
docutils                  0.18.1          py312hca03da5_3    defaults
et_xmlfile                1.1.0           py312hca03da5_1    defaults
executing                 0.8.3              pyhd3eb1b0_0    defaults
expat                     2.6.3                h313beb8_0    defaults
filelock                  3.13.1          py312hca03da5_0    defaults
flake8                    7.0.0           py312hca03da5_0    defaults
flask                     3.0.3           py312hca03da5_0    defaults
fmt                       9.1.0                h48ca7d4_1    defaults
fonttools                 4.51.0          py312h80987f9_0    defaults
freetype                  2.12.1               h1192e45_0    defaults
frozendict                2.4.2           py312hca03da5_0    defaults
frozenlist                1.4.0           py312h80987f9_0    defaults
fsspec                    2024.6.1        py312hca03da5_0    defaults
gensim                    4.3.3           py312hd77ebd4_0    defaults
gettext                   0.21.0               hbdbcc25_2    defaults
gflags                    2.2.2                h313beb8_1    defaults
giflib                    5.2.1                h80987f9_3    defaults
gitdb                     4.0.7              pyhd3eb1b0_0    defaults
gitpython                 3.1.43          py312hca03da5_0    defaults
glib                      2.78.4               h313beb8_0    defaults
glib-tools                2.78.4               h313beb8_0    defaults
glog                      0.5.0                h313beb8_1    defaults
greenlet                  3.0.1           py312h313beb8_0    defaults
gst-plugins-base          1.14.1               h313beb8_1    defaults
gstreamer                 1.14.1               h80987f9_1    defaults
h11                       0.14.0          py312hca03da5_0    defaults
h5py                      3.11.0          py312haac6407_0    defaults
hdf5                      1.12.1               h05c076b_3    defaults
heapdict                  1.0.1              pyhd3eb1b0_0    defaults
holoviews                 1.19.1          py312hca03da5_0    defaults
httpcore                  1.0.2           py312hca03da5_0    defaults
httpx                     0.27.0          py312hca03da5_0    defaults
hvplot                    0.11.0          py312hca03da5_0    defaults
hyperlink                 21.0.0             pyhd3eb1b0_0    defaults
icu                       73.1                 h313beb8_0    defaults
idna                      3.7             py312hca03da5_0    defaults
imagecodecs               2023.1.23       py312h75b721f_1    defaults
imageio                   2.33.1          py312hca03da5_0    defaults
imagesize                 1.4.1           py312hca03da5_0    defaults
imbalanced-learn          0.12.3          py312hca03da5_1    defaults
importlib-metadata        7.0.1           py312hca03da5_0    defaults
incremental               22.10.0            pyhd3eb1b0_0    defaults
inflection                0.5.1           py312hca03da5_1    defaults
iniconfig                 1.1.1              pyhd3eb1b0_0    defaults
intake                    2.0.7           py312hca03da5_0    defaults
intervaltree              3.1.0              pyhd3eb1b0_0    defaults
ipykernel                 6.28.0          py312hca03da5_0    defaults
ipython                   8.27.0          py312hca03da5_0    defaults
ipython_genutils          0.2.0              pyhd3eb1b0_1    defaults
ipywidgets                7.8.1           py312hca03da5_0    defaults
isort                     5.13.2          py312hca03da5_0    defaults
itemadapter               0.3.0              pyhd3eb1b0_0    defaults
itemloaders               1.1.0           py312hca03da5_0    defaults
itsdangerous              2.2.0           py312hca03da5_0    defaults
jaraco.classes            3.2.1              pyhd3eb1b0_0    defaults
jedi                      0.19.1          py312hca03da5_0    defaults
jellyfish                 1.0.1           py312h15d1925_0    defaults
jinja2                    3.1.4           py312hca03da5_0    defaults
jmespath                  1.0.1           py312hca03da5_0    defaults
joblib                    1.4.2           py312hca03da5_0    defaults
jpeg                      9e                   h80987f9_3    defaults
jq                        1.6                  h1a28f6b_1    defaults
json5                     0.9.6              pyhd3eb1b0_0    defaults
jsonpatch                 1.33            py312hca03da5_1    defaults
jsonpointer               2.1                pyhd3eb1b0_0    defaults
jsonschema                4.23.0          py312hca03da5_0    defaults
jsonschema-specifications 2023.7.1        py312hca03da5_0    defaults
jupyter                   1.0.0           py312hca03da5_9    defaults
jupyter-lsp               2.2.0           py312hca03da5_0    defaults
jupyter_client            8.6.0           py312hca03da5_0    defaults
jupyter_console           6.6.3           py312hca03da5_1    defaults
jupyter_core              5.7.2           py312hca03da5_0    defaults
jupyter_events            0.10.0          py312hca03da5_0    defaults
jupyter_server            2.14.1          py312hca03da5_0    defaults
jupyter_server_terminals  0.4.4           py312hca03da5_1    defaults
jupyterlab                4.2.5           py312hca03da5_0    defaults
jupyterlab-variableinspector 3.1.0           py312hca03da5_0    defaults
jupyterlab_pygments       0.1.2                      py_0    defaults
jupyterlab_server         2.27.3          py312hca03da5_0    defaults
jupyterlab_widgets        1.0.0              pyhd3eb1b0_1    defaults
jxrlib                    1.1                  h1a28f6b_2    defaults
keyring                   24.3.1          py312hca03da5_0    defaults
kiwisolver                1.4.4           py312h313beb8_0    defaults
krb5                      1.20.1               hf3e1bf2_1    defaults
lazy-object-proxy         1.10.0          py312h80987f9_0    defaults
lazy_loader               0.4             py312hca03da5_0    defaults
lcms2                     2.12                 hba8e193_0    defaults
ld64                      530                 hb29bf3f_25    defaults
ld64_osx-arm64            530                 h001ce53_25    defaults
ldid                      2.1.5                h20b2a84_3    defaults
lerc                      3.0                  hc377ac9_0    defaults
libabseil                 20240116.2      cxx17_h313beb8_0    defaults
libaec                    1.0.4                hc377ac9_1    defaults
libarchive                3.7.4                h8f13d7a_0    defaults
libavif                   0.11.1               h80987f9_0    defaults
libboost                  1.82.0               h0bc93f9_2    defaults
libbrotlicommon           1.0.9                h80987f9_8    defaults
libbrotlidec              1.0.9                h80987f9_8    defaults
libbrotlienc              1.0.9                h80987f9_8    defaults
libclang                  14.0.6          default_h1b80db6_1    defaults
libclang13                14.0.6          default_h24352ff_1    defaults
libcurl                   8.9.1                h3e2b118_0    defaults
libcxx                    14.0.6               h848a8c0_0    defaults
libdeflate                1.17                 h80987f9_1    defaults
libedit                   3.1.20230828         h80987f9_0    defaults
libev                     4.33                 h1a28f6b_1    defaults
libevent                  2.1.12               h02f6b3c_1    defaults
libffi                    3.4.4                hca03da5_1    defaults
libgfortran               5.0.0           11_3_0_hca03da5_28    defaults
libgfortran5              11.3.0              h009349e_28    defaults
libglib                   2.78.4               h0a96307_0    defaults
libgrpc                   1.62.2               h62f6fdd_0    defaults
libiconv                  1.16                 h80987f9_3    defaults
liblief                   0.12.3               h313beb8_0    defaults
libllvm14                 14.0.6               h19fdd8a_4    defaults
libmamba                  1.5.8                haeffa04_3    defaults
libmambapy                1.5.8           py312h1c5506f_3    defaults
libnghttp2                1.57.0               h62f6fdd_0    defaults
libopenblas               0.3.21               h269037a_0    defaults
libpng                    1.6.39               h80987f9_0    defaults
libpq                     12.17                h02f6b3c_0    defaults
libprotobuf               4.25.3               h514c7bf_0    defaults
libsodium                 1.0.18               h1a28f6b_0    defaults
libsolv                   0.7.24               h514c7bf_1    defaults
libspatialindex           1.9.3                hc377ac9_0    defaults
libssh2                   1.11.0               h3e2b118_0    defaults
libthrift                 0.15.0               h73c2103_2    defaults
libtiff                   4.5.1                h313beb8_0    defaults
libwebp-base              1.3.2                h80987f9_0    defaults
libxml2                   2.13.1               h0b34f26_2    defaults
libxslt                   1.1.41               hf4d3faa_0    defaults
libzopfli                 1.0.3                hc377ac9_0    defaults
linkify-it-py             2.0.0           py312hca03da5_0    defaults
llvm-openmp               14.0.6               hc6e5704_0    defaults
llvmlite                  0.43.0          py312h313beb8_0    defaults
locket                    1.0.0           py312hca03da5_0    defaults
lxml                      5.2.1           py312h1d4350b_1    defaults
lz4                       4.3.2           py312h80987f9_0    defaults
lz4-c                     1.9.4                h313beb8_1    defaults
lzo                       2.10                 h1a28f6b_2    defaults
markdown                  3.4.1           py312hca03da5_0    defaults
markdown-it-py            2.2.0           py312hca03da5_1    defaults
markupsafe                2.1.3           py312h80987f9_0    defaults
matplotlib                3.9.2           py312hca03da5_0    defaults
matplotlib-base           3.9.2           py312h2df2da3_0    defaults
matplotlib-inline         0.1.6           py312hca03da5_0    defaults
mccabe                    0.7.0              pyhd3eb1b0_0    defaults
mdit-py-plugins           0.3.0           py312hca03da5_0    defaults
mdurl                     0.1.0           py312hca03da5_0    defaults
menuinst                  2.1.2           py312hca03da5_0    defaults
mistune                   2.0.4           py312hca03da5_0    defaults
more-itertools            10.3.0          py312hca03da5_0    defaults
mpmath                    1.3.0           py312hca03da5_0    defaults
msgpack-python            1.0.3           py312h48ca7d4_0    defaults
multidict                 6.0.4           py312h80987f9_0    defaults
multipledispatch          0.6.0           py312hca03da5_0    defaults
mypy                      1.11.2          py312h80987f9_0    defaults
mypy_extensions           1.0.0           py312hca03da5_0    defaults
mysql                     5.7.24               ha71a6ea_2    defaults
navigator-updater         0.5.1           py312hca03da5_0    defaults
nbclient                  0.8.0           py312hca03da5_0    defaults
nbconvert                 7.16.4          py312hca03da5_0    defaults
nbformat                  5.10.4          py312hca03da5_0    defaults
ncurses                   6.4                  h313beb8_0    defaults
nest-asyncio              1.6.0           py312hca03da5_0    defaults
networkx                  3.3             py312hca03da5_0    defaults
nltk                      3.9.1           py312hca03da5_0    defaults
notebook                  7.2.2           py312hca03da5_1    defaults
notebook-shim             0.2.3           py312hca03da5_0    defaults
numba                     0.60.0          py312hd77ebd4_0    defaults
numexpr                   2.8.7           py312h0f3ea24_0    defaults
numpy                     1.26.4          py312h7f4fdc5_0    defaults
numpy-base                1.26.4          py312he047099_0    defaults
numpydoc                  1.7.0           py312hca03da5_0    defaults
oniguruma                 6.9.7.1              h1a28f6b_0    defaults
openjpeg                  2.5.2                h54b8e55_0    defaults
openpyxl                  3.1.5           py312h80987f9_0    defaults
openssl                   3.0.15               h80987f9_0    defaults
orc                       2.0.1                h937ddfc_0    defaults
overrides                 7.4.0           py312hca03da5_0    defaults
packaging                 24.1            py312hca03da5_0    defaults
pandas                    2.2.2           py312hd77ebd4_0    defaults
pandocfilters             1.5.0              pyhd3eb1b0_0    defaults
panel                     1.5.2           py312hca03da5_0    defaults
param                     2.1.1           py312hca03da5_0    defaults
parsel                    1.8.1           py312hca03da5_0    defaults
parso                     0.8.3              pyhd3eb1b0_0    defaults
partd                     1.4.1           py312hca03da5_0    defaults
patch                     2.7.6             h1a28f6b_1001    defaults
pathspec                  0.10.3          py312hca03da5_0    defaults
patsy                     0.5.6           py312hca03da5_0    defaults
pcre2                     10.42                hb066dcc_1    defaults
pexpect                   4.8.0              pyhd3eb1b0_3    defaults
pickleshare               0.7.5           pyhd3eb1b0_1003    defaults
pillow                    10.4.0          py312h80987f9_0    defaults
pip                       24.2            py312hca03da5_0    defaults
pkce                      1.0.3           py312hca03da5_0    defaults
pkginfo                   1.10.0          py312hca03da5_0    defaults
platformdirs              3.10.0          py312hca03da5_0    defaults
plotly                    5.24.1          py312h989b03a_0    defaults
pluggy                    1.0.0           py312hca03da5_1    defaults
ply                       3.11            py312hca03da5_1    defaults
prometheus_client         0.14.1          py312hca03da5_0    defaults
prompt-toolkit            3.0.43          py312hca03da5_0    defaults
prompt_toolkit            3.0.43               hd3eb1b0_0    defaults
protego                   0.1.16                     py_0    defaults
protobuf                  4.25.3          py312h8472c4a_0    defaults
psutil                    5.9.0           py312h80987f9_0    defaults
ptyprocess                0.7.0              pyhd3eb1b0_2    defaults
pure_eval                 0.2.2              pyhd3eb1b0_0    defaults
py-cpuinfo                9.0.0           py312hca03da5_0    defaults
py-lief                   0.12.3          py312h313beb8_0    defaults
pyarrow                   16.1.0          py312hd77ebd4_0    defaults
pyasn1                    0.4.8              pyhd3eb1b0_0    defaults
pyasn1-modules            0.2.8                      py_0    defaults
pybind11-abi              5                    hd3eb1b0_0    defaults
pycodestyle               2.11.1          py312hca03da5_0    defaults
pycosat                   0.6.6           py312h80987f9_1    defaults
pycparser                 2.21               pyhd3eb1b0_0    defaults
pyct                      0.5.0           py312hca03da5_0    defaults
pycurl                    7.45.3          py312h02f6b3c_0    defaults
pydantic                  2.8.2           py312hca03da5_0    defaults
pydantic-core             2.20.1          py312hf0e4da2_0    defaults
pydeck                    0.8.0           py312hca03da5_2    defaults
pydispatcher              2.0.5           py312hca03da5_3    defaults
pydocstyle                6.3.0           py312hca03da5_0    defaults
pyerfa                    2.0.1.4         py312ha86b861_0    defaults
pyflakes                  3.2.0           py312hca03da5_0    defaults
pygments                  2.15.1          py312hca03da5_1    defaults
pyjwt                     2.8.0           py312hca03da5_0    defaults
pylint                    2.16.2          py312hca03da5_0    defaults
pylint-venv               3.0.3           py312hca03da5_0    defaults
pyls-spyder               0.4.0              pyhd3eb1b0_0    defaults
pyobjc-core               10.1            py312h80987f9_0    defaults
pyobjc-framework-cocoa    10.1            py312hb094c41_0    defaults
pyobjc-framework-coreservices 10.1            py312hdd8dd1f_0    defaults
pyobjc-framework-fsevents 10.1            py312hca03da5_0    defaults
pyodbc                    5.1.0           py312h313beb8_0    defaults
pyopenssl                 24.2.1          py312hca03da5_0    defaults
pyparsing                 3.1.2           py312hca03da5_0    defaults
pyqt                      5.15.10         py312h313beb8_0    defaults
pyqt5-sip                 12.13.0         py312h80987f9_0    defaults
pyqtwebengine             5.15.10         py312h313beb8_0    defaults
pysocks                   1.7.1           py312hca03da5_0    defaults
pytables                  3.10.1          py312h905a39b_0    defaults
pytest                    7.4.4           py312hca03da5_0    defaults
python                    3.12.7               h99e199e_0    defaults
python-dateutil           2.9.0post0      py312hca03da5_2    defaults
python-dotenv             0.21.0          py312hca03da5_0    defaults
python-fastjsonschema     2.16.2          py312hca03da5_0    defaults
python-json-logger        2.0.7           py312hca03da5_0    defaults
python-libarchive-c       5.1                pyhd3eb1b0_0    defaults
python-lmdb               1.4.1           py312h313beb8_0    defaults
python-lsp-black          2.0.0           py312hca03da5_0    defaults
python-lsp-jsonrpc        1.1.2              pyhd3eb1b0_0    defaults
python-lsp-server         1.10.0          py312hca03da5_0    defaults
python-slugify            5.0.2              pyhd3eb1b0_0    defaults
python-tzdata             2023.3             pyhd3eb1b0_0    defaults
python.app                3               py312h80987f9_1    defaults
pytoolconfig              1.2.6           py312hca03da5_0    defaults
pytz                      2024.1          py312hca03da5_0    defaults
pyviz_comms               3.0.2           py312hca03da5_0    defaults
pywavelets                1.7.0           py312h80987f9_0    defaults
pyyaml                    6.0.1           py312h80987f9_0    defaults
pyzmq                     25.1.2          py312h313beb8_0    defaults
qdarkstyle                3.2.3              pyhd3eb1b0_0    defaults
qstylizer                 0.2.2           py312hca03da5_0    defaults
qt-main                   5.15.2              h0917680_10    defaults
qt-webengine              5.15.9               h2903aaf_7    defaults
qtawesome                 1.3.1           py312hca03da5_0    defaults
qtconsole                 5.5.1           py312hca03da5_0    defaults
qtpy                      2.4.1           py312hca03da5_0    defaults
queuelib                  1.6.2           py312hca03da5_0    defaults
re2                       2022.04.01           hc377ac9_0    defaults
readline                  8.2                  h1a28f6b_0    defaults
referencing               0.30.2          py312hca03da5_0    defaults
regex                     2024.9.11       py312h80987f9_0    defaults
reproc                    14.2.4               h313beb8_2    defaults
reproc-cpp                14.2.4               h313beb8_2    defaults
requests                  2.32.3          py312hca03da5_0    defaults
requests-file             1.5.1              pyhd3eb1b0_0    defaults
requests-toolbelt         1.0.0           py312hca03da5_0    defaults
rfc3339-validator         0.1.4           py312hca03da5_0    defaults
rfc3986-validator         0.1.1           py312hca03da5_0    defaults
rich                      13.7.1          py312hca03da5_0    defaults
rope                      1.12.0          py312hca03da5_0    defaults
rpds-py                   0.10.6          py312hf0e4da2_0    defaults
rtree                     1.0.1           py312hca03da5_0    defaults
ruamel.yaml               0.18.6          py312h80987f9_0    defaults
ruamel.yaml.clib          0.2.8           py312h80987f9_0    defaults
ruamel_yaml               0.17.21         py312h80987f9_0    defaults
s3fs                      2024.6.1        py312hca03da5_0    defaults
scikit-image              0.24.0          py312hd77ebd4_0    defaults
scikit-learn              1.5.1           py312hd77ebd4_0    defaults
scipy                     1.13.1          py312ha409365_0    defaults
scrapy                    2.11.1          py312hca03da5_0    defaults
seaborn                   0.13.2          py312hca03da5_0    defaults
semver                    3.0.2           py312hca03da5_0    defaults
send2trash                1.8.2           py312hca03da5_0    defaults
service_identity          18.1.0             pyhd3eb1b0_1    defaults
setuptools                75.1.0          py312hca03da5_0    defaults
sip                       6.7.12          py312h313beb8_0    defaults
six                       1.16.0             pyhd3eb1b0_1    defaults
smart_open                5.2.1           py312hca03da5_0    defaults
smmap                     4.0.0              pyhd3eb1b0_0    defaults
snappy                    1.2.1                h313beb8_0    defaults
sniffio                   1.3.0           py312hca03da5_0    defaults
snowballstemmer           2.2.0              pyhd3eb1b0_0    defaults
sortedcontainers          2.4.0              pyhd3eb1b0_0    defaults
soupsieve                 2.5             py312hca03da5_0    defaults
sphinx                    7.3.7           py312hca03da5_0    defaults
sphinxcontrib-applehelp   1.0.2              pyhd3eb1b0_0    defaults
sphinxcontrib-devhelp     1.0.2              pyhd3eb1b0_0    defaults
sphinxcontrib-htmlhelp    2.0.0              pyhd3eb1b0_0    defaults
sphinxcontrib-jsmath      1.0.1              pyhd3eb1b0_0    defaults
sphinxcontrib-qthelp      1.0.3              pyhd3eb1b0_0    defaults
sphinxcontrib-serializinghtml 1.1.10          py312hca03da5_0    defaults
spyder                    5.5.1           py312hca03da5_4    defaults
spyder-kernels            2.5.0           py312hca03da5_0    defaults
sqlalchemy                2.0.34          py312hbe2cdee_0    defaults
sqlite                    3.45.3               h80987f9_0    defaults
stack_data                0.2.0              pyhd3eb1b0_0    defaults
statsmodels               0.14.2          py312ha86b861_0    defaults
streamlit                 1.37.1          py312hca03da5_0    defaults
sympy                     1.13.2          py312hca03da5_0    defaults
tabulate                  0.9.0           py312hca03da5_0    defaults
tapi                      1100.0.11            h8754e6a_1    defaults
tbb                       2021.8.0             h48ca7d4_0    defaults
tblib                     1.7.0              pyhd3eb1b0_0    defaults
tenacity                  8.2.3           py312hca03da5_0    defaults
terminado                 0.17.1          py312hca03da5_0    defaults
text-unidecode            1.3                pyhd3eb1b0_0    defaults
textdistance              4.2.1              pyhd3eb1b0_0    defaults
threadpoolctl             3.5.0           py312h989b03a_0    defaults
three-merge               0.1.1              pyhd3eb1b0_0    defaults
tifffile                  2023.4.12       py312hca03da5_0    defaults
tinycss2                  1.2.1           py312hca03da5_0    defaults
tk                        8.6.14               h6ba3021_0    defaults
tldextract                5.1.2           py312hca03da5_0    defaults
toml                      0.10.2             pyhd3eb1b0_0    defaults
tomli                     2.0.1           py312hca03da5_1    defaults
tomlkit                   0.11.1          py312hca03da5_0    defaults
toolz                     0.12.0          py312hca03da5_0    defaults
tornado                   6.4.1           py312h80987f9_0    defaults
tqdm                      4.66.5          py312h989b03a_0    defaults
traitlets                 5.14.3          py312hca03da5_0    defaults
truststore                0.8.0           py312hca03da5_0    defaults
twisted                   23.10.0         py312hca03da5_0    defaults
typing-extensions         4.11.0          py312hca03da5_0    defaults
typing_extensions         4.11.0          py312hca03da5_0    defaults
tzdata                    2024b                h04d1e81_0    defaults
uc-micro-py               1.0.1           py312hca03da5_0    defaults
ujson                     5.10.0          py312h313beb8_0    defaults
unicodedata2              15.1.0          py312h80987f9_0    defaults
unidecode                 1.3.8           py312hca03da5_0    defaults
unixodbc                  2.3.11               h1a28f6b_0    defaults
urllib3                   2.2.3           py312hca03da5_0    defaults
utf8proc                  2.6.1                h80987f9_1    defaults
w3lib                     2.1.2           py312hca03da5_0    defaults
watchdog                  4.0.1           py312h80987f9_0    defaults
wcwidth                   0.2.5              pyhd3eb1b0_0    defaults
webencodings              0.5.1           py312hca03da5_2    defaults
websocket-client          1.8.0           py312hca03da5_0    defaults
werkzeug                  3.0.3           py312hca03da5_0    defaults
whatthepatch              1.0.2           py312hca03da5_0    defaults
wheel                     0.44.0          py312hca03da5_0    defaults
widgetsnbextension        3.6.6           py312hca03da5_0    defaults
wrapt                     1.14.1          py312h80987f9_0    defaults
wurlitzer                 3.0.2           py312hca03da5_0    defaults
xarray                    2023.6.0        py312hca03da5_0    defaults
xlwings                   0.32.1          py312hca03da5_0    defaults
xyzservices               2022.9.0        py312hca03da5_1    defaults
xz                        5.4.6                h80987f9_1    defaults
yaml                      0.2.5                h1a28f6b_0    defaults
yaml-cpp                  0.8.0                h313beb8_1    defaults
yapf                      0.40.2          py312hca03da5_0    defaults
yarl                      1.11.0          py312h80987f9_0    defaults
zeromq                    4.3.5                h313beb8_0    defaults
zfp                       1.0.0                h313beb8_0    defaults
zict                      3.0.0           py312hca03da5_0    defaults
zipp                      3.17.0          py312hca03da5_0    defaults
zlib                      1.2.13               h18a0788_1    defaults
zlib-ng                   2.0.7                h80987f9_0    defaults
zope                      1.0             py312hca03da5_1    defaults
zope.interface            5.4.0           py312h80987f9_0    defaults
zstandard                 0.23.0          py312h1a4646a_0    defaults
zstd                      1.5.6                hfb09047_0    defaults
```

### System Compiler & Libraries
```
[gcc --version]
Apple clang version 17.0.0 (clang-1700.0.13.5)
Target: x86_64-apple-darwin24.4.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

[g++ --version]
Apple clang version 17.0.0 (clang-1700.0.13.5)
Target: x86_64-apple-darwin24.4.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

[clang --version]
Apple clang version 17.0.0 (clang-1700.0.13.5)
Target: x86_64-apple-darwin24.4.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

[pkg-config --modversion opencv]
Package opencv was not found in the pkg-config search path.
Perhaps you should add the directory containing `opencv.pc'
to the PKG_CONFIG_PATH environment variable
Package 'opencv' not found
OpenCV not found via pkg-config.
```

### Docker / Container Info
```
[docker --version]
Docker version 28.0.4, build b8034c0

[docker images]
Cannot connect to the Docker daemon at unix:///Users/jburkart/.docker/run/docker.sock. Is the docker daemon running?

[docker ps -a]
Cannot connect to the Docker daemon at unix:///Users/jburkart/.docker/run/docker.sock. Is the docker daemon running?
```

### Relevant Environment Variables
```
CONDA_EXE=/opt/anaconda3/bin/conda
CONDA_PREFIX=/opt/anaconda3
CONDA_PROMPT_MODIFIER=(base) 
CONDA_SHLVL=1
CONDA_PYTHON_EXE=/opt/anaconda3/bin/python
CONDA_DEFAULT_ENV=base
PATH=/opt/anaconda3/bin:/opt/homebrew/bin:/Users/jburkart/mamba/condabin:/Users/jburkart/.nvm/versions/node/v23.8.0/bin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/Library/Apple/usr/bin:/Applications/iTerm.app/Contents/Resources/utilities
```

### Ollama Models
```
NAME                  ID              SIZE      MODIFIED     
qwen2.5vl:72b         05ea68274581    48 GB     15 hours ago    
r1-1776:70b           140ea940f21d    42 GB     4 months ago    
deepseek-r1:14b       ea35dfe18182    9.0 GB    5 months ago    
deepseek-r1:8b        28f8fd6cdc67    4.9 GB    5 months ago    
deepseek-r1:7b        0a8c26691023    4.7 GB    5 months ago    
deepseek-r1:1.5b      a42b25d8c10a    1.1 GB    5 months ago    
deepseek-r1:70b       0c1615a8ca32    42 GB     5 months ago    
deepseek-r1:32b       38056bbcbb2d    19 GB     5 months ago    
deepseek-r1:latest    0a8c26691023    4.7 GB    5 months ago    
```

Overview generation complete. The file 'project-overview.txt' has been created.
